{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import WD_LSTM\n",
    "from data import Corpus\n",
    "from randomize_bptt import get_bptt_sequence_lengths\n",
    "from helpers import Config, repackage_hidden, batchify, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATA = '/floyd/input/ptb/'\n",
    "CUDA = True\n",
    "LOG_INTERVAL = 50\n",
    "LR_ANNEALING_RATE = 0.25\n",
    "CONFIG_NAME = 'language_model_base'\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "args = Config(CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "train_data = batchify(corpus.train, args.batch_size, device)\n",
    "valid_data = batchify(corpus.valid, args.batch_size, device)\n",
    "test_data = batchify(corpus.test, args.batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WD_LSTM(\n",
       "  (drop): Dropout(p=0.2)\n",
       "  (encoder): Embedding(10000, 400)\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDrop(\n",
       "      (module): LSTM(400, 800)\n",
       "    )\n",
       "    (1): WeightDrop(\n",
       "      (module): LSTM(800, 800)\n",
       "    )\n",
       "    (2): WeightDrop(\n",
       "      (module): LSTM(800, 400)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=800, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WD_LSTM(\n",
    "    ntokens, \n",
    "    args.emsize,\n",
    "    args.nhid, \n",
    "    args.nlayers, \n",
    "    args.dropout, \n",
    "    weight_drop=args.weight_drop, \n",
    "    weight_tying=args.weight_tying\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = args.lr\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    model.eval()  # disable dropout\n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, args.bptt_seq_len):\n",
    "            data, targets = get_batch(data_source, i, args.bptt_seq_len)\n",
    "            output, hidden = model(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    for batch, (i, seq_len, lr_scale) in enumerate(get_bptt_sequence_lengths(\n",
    "        train_data.size(0), \n",
    "        args.bptt_seq_len, \n",
    "        args.bptt_random_scaling, \n",
    "        args.bptt_p, \n",
    "        args.bptt_s, \n",
    "        args.bptt_min_len, \n",
    "        args.bptt_max_len\n",
    "    )):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr * lr_scale\n",
    "        data, targets = get_batch(train_data, i, seq_len)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % LOG_INTERVAL == 0 and batch > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:3.2E} | ms/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // args.bptt_seq_len, lr,\n",
    "                elapsed * 1000 / LOG_INTERVAL, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py:477: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  663 batches | lr 2.00E-03 | ms/batch 172.08 | loss  7.05 | ppl  1149.87\n",
      "| epoch   1 |   100/  663 batches | lr 2.00E-03 | ms/batch 171.04 | loss  6.64 | ppl   762.05\n",
      "| epoch   1 |   150/  663 batches | lr 2.00E-03 | ms/batch 164.13 | loss  6.62 | ppl   748.85\n",
      "| epoch   1 |   200/  663 batches | lr 2.00E-03 | ms/batch 170.39 | loss  6.36 | ppl   577.08\n",
      "| epoch   1 |   250/  663 batches | lr 2.00E-03 | ms/batch 165.59 | loss  6.25 | ppl   520.09\n",
      "| epoch   1 |   300/  663 batches | lr 2.00E-03 | ms/batch 164.86 | loss  6.17 | ppl   480.10\n",
      "| epoch   1 |   350/  663 batches | lr 2.00E-03 | ms/batch 165.73 | loss  6.12 | ppl   454.14\n",
      "| epoch   1 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.38 | loss  5.95 | ppl   383.49\n",
      "| epoch   1 |   450/  663 batches | lr 2.00E-03 | ms/batch 166.22 | loss  5.92 | ppl   374.02\n",
      "| epoch   1 |   500/  663 batches | lr 2.00E-03 | ms/batch 169.25 | loss  5.93 | ppl   376.42\n",
      "| epoch   1 |   550/  663 batches | lr 2.00E-03 | ms/batch 167.15 | loss  5.79 | ppl   326.84\n",
      "| epoch   1 |   600/  663 batches | lr 2.00E-03 | ms/batch 167.41 | loss  5.79 | ppl   326.87\n",
      "| epoch   1 |   650/  663 batches | lr 2.00E-03 | ms/batch 164.17 | loss  5.63 | ppl   279.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 117.20s | valid loss  5.56 | valid ppl   259.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |    50/  663 batches | lr 2.00E-03 | ms/batch 174.55 | loss  5.64 | ppl   282.35\n",
      "| epoch   2 |   100/  663 batches | lr 2.00E-03 | ms/batch 169.03 | loss  5.56 | ppl   258.75\n",
      "| epoch   2 |   150/  663 batches | lr 2.00E-03 | ms/batch 162.28 | loss  5.54 | ppl   254.76\n",
      "| epoch   2 |   200/  663 batches | lr 2.00E-03 | ms/batch 169.10 | loss  5.47 | ppl   237.79\n",
      "| epoch   2 |   250/  663 batches | lr 2.00E-03 | ms/batch 162.60 | loss  5.45 | ppl   232.57\n",
      "| epoch   2 |   300/  663 batches | lr 2.00E-03 | ms/batch 167.01 | loss  5.45 | ppl   233.09\n",
      "| epoch   2 |   350/  663 batches | lr 2.00E-03 | ms/batch 168.78 | loss  5.44 | ppl   229.42\n",
      "| epoch   2 |   400/  663 batches | lr 2.00E-03 | ms/batch 163.27 | loss  5.30 | ppl   200.50\n",
      "| epoch   2 |   450/  663 batches | lr 2.00E-03 | ms/batch 167.47 | loss  5.29 | ppl   199.00\n",
      "| epoch   2 |   500/  663 batches | lr 2.00E-03 | ms/batch 167.08 | loss  5.36 | ppl   213.28\n",
      "| epoch   2 |   550/  663 batches | lr 2.00E-03 | ms/batch 165.73 | loss  5.26 | ppl   192.61\n",
      "| epoch   2 |   600/  663 batches | lr 2.00E-03 | ms/batch 169.85 | loss  5.24 | ppl   188.60\n",
      "| epoch   2 |   650/  663 batches | lr 2.00E-03 | ms/batch 165.04 | loss  5.12 | ppl   167.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 117.64s | valid loss  5.20 | valid ppl   182.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |    50/  663 batches | lr 2.00E-03 | ms/batch 173.72 | loss  5.25 | ppl   190.55\n",
      "| epoch   3 |   100/  663 batches | lr 2.00E-03 | ms/batch 159.46 | loss  5.20 | ppl   180.72\n",
      "| epoch   3 |   150/  663 batches | lr 2.00E-03 | ms/batch 165.04 | loss  5.21 | ppl   183.83\n",
      "| epoch   3 |   200/  663 batches | lr 2.00E-03 | ms/batch 166.05 | loss  5.13 | ppl   168.39\n",
      "| epoch   3 |   250/  663 batches | lr 2.00E-03 | ms/batch 166.67 | loss  5.14 | ppl   170.26\n",
      "| epoch   3 |   300/  663 batches | lr 2.00E-03 | ms/batch 168.53 | loss  5.14 | ppl   170.83\n",
      "| epoch   3 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.58 | loss  5.16 | ppl   174.88\n",
      "| epoch   3 |   400/  663 batches | lr 2.00E-03 | ms/batch 166.09 | loss  5.03 | ppl   153.44\n",
      "| epoch   3 |   450/  663 batches | lr 2.00E-03 | ms/batch 170.62 | loss  5.05 | ppl   155.84\n",
      "| epoch   3 |   500/  663 batches | lr 2.00E-03 | ms/batch 166.97 | loss  5.13 | ppl   168.24\n",
      "| epoch   3 |   550/  663 batches | lr 2.00E-03 | ms/batch 168.97 | loss  5.03 | ppl   153.34\n",
      "| epoch   3 |   600/  663 batches | lr 2.00E-03 | ms/batch 166.28 | loss  5.00 | ppl   149.06\n",
      "| epoch   3 |   650/  663 batches | lr 2.00E-03 | ms/batch 165.77 | loss  4.90 | ppl   134.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 117.69s | valid loss  5.06 | valid ppl   157.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |    50/  663 batches | lr 2.00E-03 | ms/batch 167.23 | loss  5.05 | ppl   156.51\n",
      "| epoch   4 |   100/  663 batches | lr 2.00E-03 | ms/batch 168.99 | loss  5.00 | ppl   148.65\n",
      "| epoch   4 |   150/  663 batches | lr 2.00E-03 | ms/batch 165.93 | loss  5.02 | ppl   151.75\n",
      "| epoch   4 |   200/  663 batches | lr 2.00E-03 | ms/batch 172.75 | loss  4.94 | ppl   139.15\n",
      "| epoch   4 |   250/  663 batches | lr 2.00E-03 | ms/batch 165.30 | loss  4.94 | ppl   139.93\n",
      "| epoch   4 |   300/  663 batches | lr 2.00E-03 | ms/batch 161.86 | loss  4.98 | ppl   145.30\n",
      "| epoch   4 |   350/  663 batches | lr 2.00E-03 | ms/batch 170.21 | loss  5.00 | ppl   147.87\n",
      "| epoch   4 |   400/  663 batches | lr 2.00E-03 | ms/batch 158.06 | loss  4.88 | ppl   131.46\n",
      "| epoch   4 |   450/  663 batches | lr 2.00E-03 | ms/batch 169.45 | loss  4.90 | ppl   134.68\n",
      "| epoch   4 |   500/  663 batches | lr 2.00E-03 | ms/batch 168.19 | loss  4.96 | ppl   143.29\n",
      "| epoch   4 |   550/  663 batches | lr 2.00E-03 | ms/batch 163.49 | loss  4.90 | ppl   134.13\n",
      "| epoch   4 |   600/  663 batches | lr 2.00E-03 | ms/batch 166.15 | loss  4.84 | ppl   126.05\n",
      "| epoch   4 |   650/  663 batches | lr 2.00E-03 | ms/batch 168.69 | loss  4.78 | ppl   118.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 117.74s | valid loss  4.95 | valid ppl   141.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |    50/  663 batches | lr 2.00E-03 | ms/batch 169.85 | loss  4.92 | ppl   137.39\n",
      "| epoch   5 |   100/  663 batches | lr 2.00E-03 | ms/batch 167.98 | loss  4.87 | ppl   130.60\n",
      "| epoch   5 |   150/  663 batches | lr 2.00E-03 | ms/batch 169.98 | loss  4.90 | ppl   134.69\n",
      "| epoch   5 |   200/  663 batches | lr 2.00E-03 | ms/batch 159.53 | loss  4.79 | ppl   120.83\n",
      "| epoch   5 |   250/  663 batches | lr 2.00E-03 | ms/batch 162.82 | loss  4.82 | ppl   123.94\n",
      "| epoch   5 |   300/  663 batches | lr 2.00E-03 | ms/batch 167.73 | loss  4.85 | ppl   127.96\n",
      "| epoch   5 |   350/  663 batches | lr 2.00E-03 | ms/batch 165.24 | loss  4.88 | ppl   131.50\n",
      "| epoch   5 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.75 | loss  4.76 | ppl   116.85\n",
      "| epoch   5 |   450/  663 batches | lr 2.00E-03 | ms/batch 168.88 | loss  4.78 | ppl   118.74\n",
      "| epoch   5 |   500/  663 batches | lr 2.00E-03 | ms/batch 168.21 | loss  4.87 | ppl   130.56\n",
      "| epoch   5 |   550/  663 batches | lr 2.00E-03 | ms/batch 166.98 | loss  4.78 | ppl   119.69\n",
      "| epoch   5 |   600/  663 batches | lr 2.00E-03 | ms/batch 158.20 | loss  4.73 | ppl   113.71\n",
      "| epoch   5 |   650/  663 batches | lr 2.00E-03 | ms/batch 168.27 | loss  4.67 | ppl   106.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 117.65s | valid loss  4.88 | valid ppl   131.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |    50/  663 batches | lr 2.00E-03 | ms/batch 169.33 | loss  4.81 | ppl   122.22\n",
      "| epoch   6 |   100/  663 batches | lr 2.00E-03 | ms/batch 167.33 | loss  4.77 | ppl   118.13\n",
      "| epoch   6 |   150/  663 batches | lr 2.00E-03 | ms/batch 168.77 | loss  4.81 | ppl   122.51\n",
      "| epoch   6 |   200/  663 batches | lr 2.00E-03 | ms/batch 164.25 | loss  4.70 | ppl   109.93\n",
      "| epoch   6 |   250/  663 batches | lr 2.00E-03 | ms/batch 162.09 | loss  4.71 | ppl   110.85\n",
      "| epoch   6 |   300/  663 batches | lr 2.00E-03 | ms/batch 167.47 | loss  4.76 | ppl   116.20\n",
      "| epoch   6 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.17 | loss  4.78 | ppl   119.02\n",
      "| epoch   6 |   400/  663 batches | lr 2.00E-03 | ms/batch 167.76 | loss  4.67 | ppl   106.91\n",
      "| epoch   6 |   450/  663 batches | lr 2.00E-03 | ms/batch 164.97 | loss  4.70 | ppl   109.69\n",
      "| epoch   6 |   500/  663 batches | lr 2.00E-03 | ms/batch 166.50 | loss  4.76 | ppl   117.30\n",
      "| epoch   6 |   550/  663 batches | lr 2.00E-03 | ms/batch 166.33 | loss  4.70 | ppl   110.37\n",
      "| epoch   6 |   600/  663 batches | lr 2.00E-03 | ms/batch 167.57 | loss  4.64 | ppl   103.36\n",
      "| epoch   6 |   650/  663 batches | lr 2.00E-03 | ms/batch 165.77 | loss  4.59 | ppl    98.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 117.79s | valid loss  4.83 | valid ppl   125.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |    50/  663 batches | lr 2.00E-03 | ms/batch 171.66 | loss  4.72 | ppl   112.06\n",
      "| epoch   7 |   100/  663 batches | lr 2.00E-03 | ms/batch 159.76 | loss  4.70 | ppl   109.96\n",
      "| epoch   7 |   150/  663 batches | lr 2.00E-03 | ms/batch 165.89 | loss  4.73 | ppl   113.65\n",
      "| epoch   7 |   200/  663 batches | lr 2.00E-03 | ms/batch 167.21 | loss  4.62 | ppl   101.53\n",
      "| epoch   7 |   250/  663 batches | lr 2.00E-03 | ms/batch 167.67 | loss  4.64 | ppl   103.86\n",
      "| epoch   7 |   300/  663 batches | lr 2.00E-03 | ms/batch 165.33 | loss  4.68 | ppl   107.37\n",
      "| epoch   7 |   350/  663 batches | lr 2.00E-03 | ms/batch 167.44 | loss  4.71 | ppl   111.35\n",
      "| epoch   7 |   400/  663 batches | lr 2.00E-03 | ms/batch 166.44 | loss  4.59 | ppl    98.80\n",
      "| epoch   7 |   450/  663 batches | lr 2.00E-03 | ms/batch 167.96 | loss  4.63 | ppl   102.39\n",
      "| epoch   7 |   500/  663 batches | lr 2.00E-03 | ms/batch 168.00 | loss  4.70 | ppl   110.22\n",
      "| epoch   7 |   550/  663 batches | lr 2.00E-03 | ms/batch 164.39 | loss  4.64 | ppl   103.24\n",
      "| epoch   7 |   600/  663 batches | lr 2.00E-03 | ms/batch 157.36 | loss  4.57 | ppl    96.30\n",
      "| epoch   7 |   650/  663 batches | lr 2.00E-03 | ms/batch 166.40 | loss  4.51 | ppl    91.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 117.86s | valid loss  4.78 | valid ppl   119.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |    50/  663 batches | lr 2.00E-03 | ms/batch 169.63 | loss  4.65 | ppl   104.14\n",
      "| epoch   8 |   100/  663 batches | lr 2.00E-03 | ms/batch 167.34 | loss  4.64 | ppl   103.33\n",
      "| epoch   8 |   150/  663 batches | lr 2.00E-03 | ms/batch 168.55 | loss  4.66 | ppl   106.13\n",
      "| epoch   8 |   200/  663 batches | lr 2.00E-03 | ms/batch 169.41 | loss  4.56 | ppl    95.79\n",
      "| epoch   8 |   250/  663 batches | lr 2.00E-03 | ms/batch 167.47 | loss  4.56 | ppl    96.03\n",
      "| epoch   8 |   300/  663 batches | lr 2.00E-03 | ms/batch 168.94 | loss  4.62 | ppl   101.80\n",
      "| epoch   8 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.09 | loss  4.64 | ppl   103.54\n",
      "| epoch   8 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.60 | loss  4.52 | ppl    91.66\n",
      "| epoch   8 |   450/  663 batches | lr 2.00E-03 | ms/batch 164.08 | loss  4.56 | ppl    96.03\n",
      "| epoch   8 |   500/  663 batches | lr 2.00E-03 | ms/batch 169.38 | loss  4.66 | ppl   105.94\n",
      "| epoch   8 |   550/  663 batches | lr 2.00E-03 | ms/batch 164.78 | loss  4.56 | ppl    95.21\n",
      "| epoch   8 |   600/  663 batches | lr 2.00E-03 | ms/batch 166.96 | loss  4.51 | ppl    90.96\n",
      "| epoch   8 |   650/  663 batches | lr 2.00E-03 | ms/batch 166.72 | loss  4.46 | ppl    86.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 117.76s | valid loss  4.75 | valid ppl   115.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |    50/  663 batches | lr 2.00E-03 | ms/batch 167.05 | loss  4.58 | ppl    97.86\n",
      "| epoch   9 |   100/  663 batches | lr 2.00E-03 | ms/batch 164.78 | loss  4.57 | ppl    96.89\n",
      "| epoch   9 |   150/  663 batches | lr 2.00E-03 | ms/batch 168.21 | loss  4.61 | ppl   100.76\n",
      "| epoch   9 |   200/  663 batches | lr 2.00E-03 | ms/batch 167.87 | loss  4.49 | ppl    89.34\n",
      "| epoch   9 |   250/  663 batches | lr 2.00E-03 | ms/batch 163.35 | loss  4.52 | ppl    92.06\n",
      "| epoch   9 |   300/  663 batches | lr 2.00E-03 | ms/batch 167.08 | loss  4.55 | ppl    95.01\n",
      "| epoch   9 |   350/  663 batches | lr 2.00E-03 | ms/batch 167.72 | loss  4.60 | ppl    99.33\n",
      "| epoch   9 |   400/  663 batches | lr 2.00E-03 | ms/batch 167.81 | loss  4.47 | ppl    87.38\n",
      "| epoch   9 |   450/  663 batches | lr 2.00E-03 | ms/batch 164.02 | loss  4.52 | ppl    92.08\n",
      "| epoch   9 |   500/  663 batches | lr 2.00E-03 | ms/batch 161.26 | loss  4.59 | ppl    98.76\n",
      "| epoch   9 |   550/  663 batches | lr 2.00E-03 | ms/batch 162.28 | loss  4.54 | ppl    93.82\n",
      "| epoch   9 |   600/  663 batches | lr 2.00E-03 | ms/batch 166.17 | loss  4.43 | ppl    84.05\n",
      "| epoch   9 |   650/  663 batches | lr 2.00E-03 | ms/batch 166.35 | loss  4.41 | ppl    82.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 117.85s | valid loss  4.71 | valid ppl   111.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |    50/  663 batches | lr 2.00E-03 | ms/batch 172.25 | loss  4.53 | ppl    93.18\n",
      "| epoch  10 |   100/  663 batches | lr 2.00E-03 | ms/batch 165.10 | loss  4.54 | ppl    93.26\n",
      "| epoch  10 |   150/  663 batches | lr 2.00E-03 | ms/batch 169.81 | loss  4.57 | ppl    96.30\n",
      "| epoch  10 |   200/  663 batches | lr 2.00E-03 | ms/batch 165.08 | loss  4.44 | ppl    85.10\n",
      "| epoch  10 |   250/  663 batches | lr 2.00E-03 | ms/batch 166.68 | loss  4.47 | ppl    87.13\n",
      "| epoch  10 |   300/  663 batches | lr 2.00E-03 | ms/batch 166.19 | loss  4.52 | ppl    91.80\n",
      "| epoch  10 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.68 | loss  4.53 | ppl    93.16\n",
      "| epoch  10 |   400/  663 batches | lr 2.00E-03 | ms/batch 167.06 | loss  4.43 | ppl    84.06\n",
      "| epoch  10 |   450/  663 batches | lr 2.00E-03 | ms/batch 169.33 | loss  4.47 | ppl    87.05\n",
      "| epoch  10 |   500/  663 batches | lr 2.00E-03 | ms/batch 166.80 | loss  4.58 | ppl    97.18\n",
      "| epoch  10 |   550/  663 batches | lr 2.00E-03 | ms/batch 170.39 | loss  4.45 | ppl    85.29\n",
      "| epoch  10 |   600/  663 batches | lr 2.00E-03 | ms/batch 168.55 | loss  4.41 | ppl    82.57\n",
      "| epoch  10 |   650/  663 batches | lr 2.00E-03 | ms/batch 161.21 | loss  4.36 | ppl    78.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 117.57s | valid loss  4.70 | valid ppl   109.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |    50/  663 batches | lr 2.00E-03 | ms/batch 170.46 | loss  4.49 | ppl    88.86\n",
      "| epoch  11 |   100/  663 batches | lr 2.00E-03 | ms/batch 169.00 | loss  4.49 | ppl    89.52\n",
      "| epoch  11 |   150/  663 batches | lr 2.00E-03 | ms/batch 165.09 | loss  4.53 | ppl    92.91\n",
      "| epoch  11 |   200/  663 batches | lr 2.00E-03 | ms/batch 163.29 | loss  4.39 | ppl    80.84\n",
      "| epoch  11 |   250/  663 batches | lr 2.00E-03 | ms/batch 168.45 | loss  4.43 | ppl    84.27\n",
      "| epoch  11 |   300/  663 batches | lr 2.00E-03 | ms/batch 172.48 | loss  4.49 | ppl    88.98\n",
      "| epoch  11 |   350/  663 batches | lr 2.00E-03 | ms/batch 169.56 | loss  4.50 | ppl    89.72\n",
      "| epoch  11 |   400/  663 batches | lr 2.00E-03 | ms/batch 167.89 | loss  4.38 | ppl    80.10\n",
      "| epoch  11 |   450/  663 batches | lr 2.00E-03 | ms/batch 166.14 | loss  4.44 | ppl    84.96\n",
      "| epoch  11 |   500/  663 batches | lr 2.00E-03 | ms/batch 163.34 | loss  4.54 | ppl    94.00\n",
      "| epoch  11 |   550/  663 batches | lr 2.00E-03 | ms/batch 167.48 | loss  4.42 | ppl    83.42\n",
      "| epoch  11 |   600/  663 batches | lr 2.00E-03 | ms/batch 170.39 | loss  4.37 | ppl    79.32\n",
      "| epoch  11 |   650/  663 batches | lr 2.00E-03 | ms/batch 164.35 | loss  4.34 | ppl    76.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 117.60s | valid loss  4.67 | valid ppl   106.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |    50/  663 batches | lr 2.00E-03 | ms/batch 169.39 | loss  4.44 | ppl    84.98\n",
      "| epoch  12 |   100/  663 batches | lr 2.00E-03 | ms/batch 169.28 | loss  4.46 | ppl    86.65\n",
      "| epoch  12 |   150/  663 batches | lr 2.00E-03 | ms/batch 168.86 | loss  4.49 | ppl    89.47\n",
      "| epoch  12 |   200/  663 batches | lr 2.00E-03 | ms/batch 162.85 | loss  4.36 | ppl    78.27\n",
      "| epoch  12 |   250/  663 batches | lr 2.00E-03 | ms/batch 169.80 | loss  4.39 | ppl    80.34\n",
      "| epoch  12 |   300/  663 batches | lr 2.00E-03 | ms/batch 165.69 | loss  4.46 | ppl    86.16\n",
      "| epoch  12 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.49 | loss  4.46 | ppl    86.76\n",
      "| epoch  12 |   400/  663 batches | lr 2.00E-03 | ms/batch 165.60 | loss  4.35 | ppl    77.78\n",
      "| epoch  12 |   450/  663 batches | lr 2.00E-03 | ms/batch 163.90 | loss  4.41 | ppl    82.41\n",
      "| epoch  12 |   500/  663 batches | lr 2.00E-03 | ms/batch 167.20 | loss  4.50 | ppl    90.22\n",
      "| epoch  12 |   550/  663 batches | lr 2.00E-03 | ms/batch 167.42 | loss  4.41 | ppl    82.33\n",
      "| epoch  12 |   600/  663 batches | lr 2.00E-03 | ms/batch 166.57 | loss  4.32 | ppl    75.15\n",
      "| epoch  12 |   650/  663 batches | lr 2.00E-03 | ms/batch 164.01 | loss  4.30 | ppl    73.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 117.69s | valid loss  4.66 | valid ppl   106.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |    50/  663 batches | lr 2.00E-03 | ms/batch 171.00 | loss  4.41 | ppl    82.30\n",
      "| epoch  13 |   100/  663 batches | lr 2.00E-03 | ms/batch 162.51 | loss  4.43 | ppl    83.85\n",
      "| epoch  13 |   150/  663 batches | lr 2.00E-03 | ms/batch 169.38 | loss  4.47 | ppl    87.72\n",
      "| epoch  13 |   200/  663 batches | lr 2.00E-03 | ms/batch 165.74 | loss  4.34 | ppl    77.00\n",
      "| epoch  13 |   250/  663 batches | lr 2.00E-03 | ms/batch 160.14 | loss  4.36 | ppl    78.17\n",
      "| epoch  13 |   300/  663 batches | lr 2.00E-03 | ms/batch 168.25 | loss  4.41 | ppl    81.86\n",
      "| epoch  13 |   350/  663 batches | lr 2.00E-03 | ms/batch 166.71 | loss  4.44 | ppl    84.88\n",
      "| epoch  13 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.80 | loss  4.32 | ppl    75.38\n",
      "| epoch  13 |   450/  663 batches | lr 2.00E-03 | ms/batch 169.21 | loss  4.37 | ppl    78.77\n",
      "| epoch  13 |   500/  663 batches | lr 2.00E-03 | ms/batch 162.03 | loss  4.46 | ppl    86.79\n",
      "| epoch  13 |   550/  663 batches | lr 2.00E-03 | ms/batch 165.09 | loss  4.41 | ppl    82.22\n",
      "| epoch  13 |   600/  663 batches | lr 2.00E-03 | ms/batch 161.36 | loss  4.28 | ppl    72.05\n",
      "| epoch  13 |   650/  663 batches | lr 2.00E-03 | ms/batch 161.92 | loss  4.29 | ppl    72.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 117.89s | valid loss  4.63 | valid ppl   102.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |    50/  663 batches | lr 2.00E-03 | ms/batch 165.14 | loss  4.38 | ppl    80.23\n",
      "| epoch  14 |   100/  663 batches | lr 2.00E-03 | ms/batch 160.27 | loss  4.38 | ppl    79.50\n",
      "| epoch  14 |   150/  663 batches | lr 2.00E-03 | ms/batch 165.25 | loss  4.45 | ppl    85.71\n",
      "| epoch  14 |   200/  663 batches | lr 2.00E-03 | ms/batch 167.99 | loss  4.31 | ppl    74.76\n",
      "| epoch  14 |   250/  663 batches | lr 2.00E-03 | ms/batch 163.59 | loss  4.35 | ppl    77.39\n",
      "| epoch  14 |   300/  663 batches | lr 2.00E-03 | ms/batch 167.74 | loss  4.37 | ppl    79.36\n",
      "| epoch  14 |   350/  663 batches | lr 2.00E-03 | ms/batch 169.21 | loss  4.42 | ppl    82.98\n",
      "| epoch  14 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.57 | loss  4.29 | ppl    73.04\n",
      "| epoch  14 |   450/  663 batches | lr 2.00E-03 | ms/batch 168.24 | loss  4.35 | ppl    77.69\n",
      "| epoch  14 |   500/  663 batches | lr 2.00E-03 | ms/batch 165.94 | loss  4.43 | ppl    83.69\n",
      "| epoch  14 |   550/  663 batches | lr 2.00E-03 | ms/batch 164.17 | loss  4.39 | ppl    80.37\n",
      "| epoch  14 |   600/  663 batches | lr 2.00E-03 | ms/batch 168.22 | loss  4.26 | ppl    71.09\n",
      "| epoch  14 |   650/  663 batches | lr 2.00E-03 | ms/batch 166.67 | loss  4.25 | ppl    69.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 117.71s | valid loss  4.62 | valid ppl   100.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |    50/  663 batches | lr 2.00E-03 | ms/batch 173.16 | loss  4.36 | ppl    78.01\n",
      "| epoch  15 |   100/  663 batches | lr 2.00E-03 | ms/batch 163.98 | loss  4.39 | ppl    80.39\n",
      "| epoch  15 |   150/  663 batches | lr 2.00E-03 | ms/batch 168.07 | loss  4.41 | ppl    82.21\n",
      "| epoch  15 |   200/  663 batches | lr 2.00E-03 | ms/batch 167.93 | loss  4.31 | ppl    74.11\n",
      "| epoch  15 |   250/  663 batches | lr 2.00E-03 | ms/batch 168.15 | loss  4.31 | ppl    74.28\n",
      "| epoch  15 |   300/  663 batches | lr 2.00E-03 | ms/batch 165.22 | loss  4.37 | ppl    78.67\n",
      "| epoch  15 |   350/  663 batches | lr 2.00E-03 | ms/batch 168.74 | loss  4.38 | ppl    80.08\n",
      "| epoch  15 |   400/  663 batches | lr 2.00E-03 | ms/batch 168.44 | loss  4.26 | ppl    70.48\n",
      "| epoch  15 |   450/  663 batches | lr 2.00E-03 | ms/batch 166.91 | loss  4.34 | ppl    76.44\n",
      "| epoch  15 |   500/  663 batches | lr 2.00E-03 | ms/batch 164.30 | loss  4.44 | ppl    84.36\n",
      "| epoch  15 |   550/  663 batches | lr 2.00E-03 | ms/batch 165.55 | loss  4.33 | ppl    76.17\n",
      "| epoch  15 |   600/  663 batches | lr 2.00E-03 | ms/batch 169.66 | loss  4.26 | ppl    70.96\n",
      "| epoch  15 |   650/  663 batches | lr 2.00E-03 | ms/batch 165.50 | loss  4.23 | ppl    68.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 117.49s | valid loss  4.61 | valid ppl   100.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |    50/  663 batches | lr 2.00E-03 | ms/batch 172.04 | loss  4.33 | ppl    76.16\n",
      "| epoch  16 |   100/  663 batches | lr 2.00E-03 | ms/batch 164.93 | loss  4.36 | ppl    78.44\n",
      "| epoch  16 |   150/  663 batches | lr 2.00E-03 | ms/batch 166.05 | loss  4.40 | ppl    81.34\n",
      "| epoch  16 |   200/  663 batches | lr 2.00E-03 | ms/batch 161.13 | loss  4.27 | ppl    71.77\n",
      "| epoch  16 |   250/  663 batches | lr 2.00E-03 | ms/batch 169.13 | loss  4.30 | ppl    73.86\n",
      "| epoch  16 |   300/  663 batches | lr 2.00E-03 | ms/batch 166.19 | loss  4.35 | ppl    77.16\n",
      "| epoch  16 |   350/  663 batches | lr 2.00E-03 | ms/batch 165.01 | loss  4.37 | ppl    78.70\n",
      "| epoch  16 |   400/  663 batches | lr 2.00E-03 | ms/batch 170.18 | loss  4.25 | ppl    70.27\n",
      "| epoch  16 |   450/  663 batches | lr 2.00E-03 | ms/batch 171.60 | loss  4.30 | ppl    73.64\n",
      "| epoch  16 |   500/  663 batches | lr 2.00E-03 | ms/batch 164.38 | loss  4.41 | ppl    81.96\n",
      "| epoch  16 |   550/  663 batches | lr 2.00E-03 | ms/batch 170.44 | loss  4.31 | ppl    74.77\n",
      "| epoch  16 |   600/  663 batches | lr 2.00E-03 | ms/batch 163.89 | loss  4.23 | ppl    69.04\n",
      "| epoch  16 |   650/  663 batches | lr 2.00E-03 | ms/batch 169.12 | loss  4.21 | ppl    67.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 117.76s | valid loss  4.61 | valid ppl   100.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |    50/  663 batches | lr 5.00E-04 | ms/batch 169.85 | loss  4.32 | ppl    75.08\n",
      "| epoch  17 |   100/  663 batches | lr 5.00E-04 | ms/batch 165.64 | loss  4.32 | ppl    75.10\n",
      "| epoch  17 |   150/  663 batches | lr 5.00E-04 | ms/batch 167.76 | loss  4.36 | ppl    77.87\n",
      "| epoch  17 |   200/  663 batches | lr 5.00E-04 | ms/batch 165.30 | loss  4.19 | ppl    66.04\n",
      "| epoch  17 |   250/  663 batches | lr 5.00E-04 | ms/batch 167.77 | loss  4.20 | ppl    66.42\n",
      "| epoch  17 |   300/  663 batches | lr 5.00E-04 | ms/batch 167.50 | loss  4.23 | ppl    69.03\n",
      "| epoch  17 |   350/  663 batches | lr 5.00E-04 | ms/batch 168.93 | loss  4.24 | ppl    69.46\n",
      "| epoch  17 |   400/  663 batches | lr 5.00E-04 | ms/batch 167.30 | loss  4.10 | ppl    60.13\n",
      "| epoch  17 |   450/  663 batches | lr 5.00E-04 | ms/batch 169.61 | loss  4.12 | ppl    61.83\n",
      "| epoch  17 |   500/  663 batches | lr 5.00E-04 | ms/batch 165.82 | loss  4.23 | ppl    68.81\n",
      "| epoch  17 |   550/  663 batches | lr 5.00E-04 | ms/batch 163.90 | loss  4.11 | ppl    61.13\n",
      "| epoch  17 |   600/  663 batches | lr 5.00E-04 | ms/batch 163.68 | loss  4.01 | ppl    55.30\n",
      "| epoch  17 |   650/  663 batches | lr 5.00E-04 | ms/batch 167.09 | loss  3.96 | ppl    52.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 117.94s | valid loss  4.54 | valid ppl    93.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |    50/  663 batches | lr 5.00E-04 | ms/batch 170.58 | loss  4.21 | ppl    67.54\n",
      "| epoch  18 |   100/  663 batches | lr 5.00E-04 | ms/batch 169.46 | loss  4.23 | ppl    68.84\n",
      "| epoch  18 |   150/  663 batches | lr 5.00E-04 | ms/batch 160.71 | loss  4.27 | ppl    71.46\n",
      "| epoch  18 |   200/  663 batches | lr 5.00E-04 | ms/batch 167.37 | loss  4.12 | ppl    61.71\n",
      "| epoch  18 |   250/  663 batches | lr 5.00E-04 | ms/batch 167.87 | loss  4.12 | ppl    61.84\n",
      "| epoch  18 |   300/  663 batches | lr 5.00E-04 | ms/batch 168.44 | loss  4.17 | ppl    64.64\n",
      "| epoch  18 |   350/  663 batches | lr 5.00E-04 | ms/batch 171.02 | loss  4.17 | ppl    64.76\n",
      "| epoch  18 |   400/  663 batches | lr 5.00E-04 | ms/batch 165.00 | loss  4.04 | ppl    56.79\n",
      "| epoch  18 |   450/  663 batches | lr 5.00E-04 | ms/batch 164.22 | loss  4.09 | ppl    59.74\n",
      "| epoch  18 |   500/  663 batches | lr 5.00E-04 | ms/batch 166.39 | loss  4.19 | ppl    66.11\n",
      "| epoch  18 |   550/  663 batches | lr 5.00E-04 | ms/batch 161.76 | loss  4.09 | ppl    59.74\n",
      "| epoch  18 |   600/  663 batches | lr 5.00E-04 | ms/batch 169.27 | loss  3.99 | ppl    53.89\n",
      "| epoch  18 |   650/  663 batches | lr 5.00E-04 | ms/batch 169.50 | loss  3.94 | ppl    51.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 117.71s | valid loss  4.53 | valid ppl    92.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |    50/  663 batches | lr 5.00E-04 | ms/batch 168.03 | loss  4.17 | ppl    64.40\n",
      "| epoch  19 |   100/  663 batches | lr 5.00E-04 | ms/batch 168.90 | loss  4.18 | ppl    65.68\n",
      "| epoch  19 |   150/  663 batches | lr 5.00E-04 | ms/batch 167.81 | loss  4.23 | ppl    68.42\n",
      "| epoch  19 |   200/  663 batches | lr 5.00E-04 | ms/batch 164.77 | loss  4.09 | ppl    59.50\n",
      "| epoch  19 |   250/  663 batches | lr 5.00E-04 | ms/batch 168.94 | loss  4.09 | ppl    59.75\n",
      "| epoch  19 |   300/  663 batches | lr 5.00E-04 | ms/batch 165.07 | loss  4.14 | ppl    62.60\n",
      "| epoch  19 |   350/  663 batches | lr 5.00E-04 | ms/batch 168.85 | loss  4.14 | ppl    62.99\n",
      "| epoch  19 |   400/  663 batches | lr 5.00E-04 | ms/batch 170.10 | loss  4.01 | ppl    55.04\n",
      "| epoch  19 |   450/  663 batches | lr 5.00E-04 | ms/batch 167.06 | loss  4.08 | ppl    58.94\n",
      "| epoch  19 |   500/  663 batches | lr 5.00E-04 | ms/batch 166.61 | loss  4.17 | ppl    64.82\n",
      "| epoch  19 |   550/  663 batches | lr 5.00E-04 | ms/batch 166.14 | loss  4.04 | ppl    57.09\n",
      "| epoch  19 |   600/  663 batches | lr 5.00E-04 | ms/batch 169.94 | loss  3.98 | ppl    53.46\n",
      "| epoch  19 |   650/  663 batches | lr 5.00E-04 | ms/batch 164.86 | loss  3.93 | ppl    50.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 117.56s | valid loss  4.52 | valid ppl    92.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |    50/  663 batches | lr 5.00E-04 | ms/batch 172.46 | loss  4.14 | ppl    62.70\n",
      "| epoch  20 |   100/  663 batches | lr 5.00E-04 | ms/batch 166.84 | loss  4.16 | ppl    64.24\n",
      "| epoch  20 |   150/  663 batches | lr 5.00E-04 | ms/batch 159.98 | loss  4.20 | ppl    66.84\n",
      "| epoch  20 |   200/  663 batches | lr 5.00E-04 | ms/batch 169.36 | loss  4.06 | ppl    57.89\n",
      "| epoch  20 |   250/  663 batches | lr 5.00E-04 | ms/batch 169.20 | loss  4.07 | ppl    58.63\n",
      "| epoch  20 |   300/  663 batches | lr 5.00E-04 | ms/batch 168.22 | loss  4.12 | ppl    61.26\n",
      "| epoch  20 |   350/  663 batches | lr 5.00E-04 | ms/batch 164.93 | loss  4.12 | ppl    61.57\n",
      "| epoch  20 |   400/  663 batches | lr 5.00E-04 | ms/batch 169.76 | loss  4.00 | ppl    54.56\n",
      "| epoch  20 |   450/  663 batches | lr 5.00E-04 | ms/batch 162.02 | loss  4.06 | ppl    57.89\n",
      "| epoch  20 |   500/  663 batches | lr 5.00E-04 | ms/batch 166.13 | loss  4.15 | ppl    63.73\n",
      "| epoch  20 |   550/  663 batches | lr 5.00E-04 | ms/batch 168.93 | loss  4.05 | ppl    57.26\n",
      "| epoch  20 |   600/  663 batches | lr 5.00E-04 | ms/batch 170.58 | loss  3.96 | ppl    52.46\n",
      "| epoch  20 |   650/  663 batches | lr 5.00E-04 | ms/batch 166.23 | loss  3.93 | ppl    50.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 117.63s | valid loss  4.52 | valid ppl    91.78\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1e20\n",
    "try:\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(valid_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "            epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        if val_loss < best_val_loss:\n",
    "            with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            lr *= LR_ANNEALING_RATE\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  4.49 | test ppl    88.94\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
