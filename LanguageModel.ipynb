{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import WD_LSTM\n",
    "from data import Corpus\n",
    "from randomize_bptt import get_bptt_sequence_lengths\n",
    "from helpers import Config, repackage_hidden, batchify, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATA = '/floyd/input/ptb/'\n",
    "CUDA = True\n",
    "LOG_INTERVAL = 100\n",
    "LR_ANNEALING_RATE = 0.25\n",
    "CONFIG_NAME = 'language_model_base'\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "args = Config(CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "train_data = batchify(corpus.train, args.batch_size, device)\n",
    "valid_data = batchify(corpus.valid, args.eval_batch_size, device)\n",
    "test_data = batchify(corpus.test, args.test_batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WD_LSTM(\n",
       "  (variational_dropout): VariationalDropout()\n",
       "  (encoder): Embedding(10000, 400)\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDrop(\n",
       "      (module): LSTM(400, 1150)\n",
       "    )\n",
       "    (1): WeightDrop(\n",
       "      (module): LSTM(1150, 1150)\n",
       "    )\n",
       "    (2): WeightDrop(\n",
       "      (module): LSTM(1150, 400)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=400, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WD_LSTM(\n",
    "    ntoken=ntokens, \n",
    "    ninp=args.emsize,\n",
    "    nhid=args.nhid, \n",
    "    nlayers=args.nlayers, \n",
    "    dropout=args.dropout,\n",
    "    dropout_h=args.dropout_h,\n",
    "    dropout_i=args.dropout_i,\n",
    "    dropout_e=args.dropout_e,\n",
    "    weight_drop=args.weight_drop, \n",
    "    weight_tying=args.weight_tying\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = args.lr\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source, batch_size):\n",
    "    model.eval()  # disable dropout\n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, args.bptt_seq_len):\n",
    "            data, targets = get_batch(data_source, i, args.bptt_seq_len)\n",
    "            output, hidden, _, _ = model(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_tar_regularization_loss(outputs, dropped_outputs):\n",
    "    reg_loss = 0\n",
    "    for i in range(len(dropped_outputs[-1])):\n",
    "        reg_loss += args.alpha * dropped_outputs[-1][i].pow(2).mean()\n",
    "        if i >= 1:\n",
    "            reg_loss += args.beta * (outputs[-1][i] - outputs[-1][i - 1]).pow(2).mean()\n",
    "    return reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    for batch, (i, seq_len, lr_scale) in enumerate(get_bptt_sequence_lengths(\n",
    "        train_data.size(0), \n",
    "        args.bptt_seq_len, \n",
    "        args.bptt_random_scaling, \n",
    "        args.bptt_p, \n",
    "        args.bptt_s, \n",
    "        args.bptt_min_len\n",
    "    )):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr * lr_scale\n",
    "        data, targets = get_batch(train_data, i, seq_len)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden, outputs, dropped_outputs = model(data, hidden)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        unregularized_loss = criterion(output_flat, targets)\n",
    "        regularized_loss = unregularized_loss + ar_tar_regularization_loss(outputs, dropped_outputs)\n",
    "        regularized_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        total_loss += unregularized_loss.item()\n",
    "        if batch % LOG_INTERVAL == 0 and batch > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:3.2E} | ms/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // args.bptt_seq_len, lr,\n",
    "                elapsed * 1000 / LOG_INTERVAL, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py:477: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/  663 batches | lr 4.00E-03 | ms/batch 223.71 | loss  8.00 | ppl  2992.13\n",
      "| epoch   1 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.19 | loss  6.46 | ppl   636.60\n",
      "| epoch   1 |   300/  663 batches | lr 4.00E-03 | ms/batch 215.15 | loss  6.35 | ppl   570.15\n",
      "| epoch   1 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.27 | loss  6.20 | ppl   494.54\n",
      "| epoch   1 |   500/  663 batches | lr 4.00E-03 | ms/batch 216.34 | loss  6.09 | ppl   439.95\n",
      "| epoch   1 |   600/  663 batches | lr 4.00E-03 | ms/batch 216.64 | loss  5.95 | ppl   383.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 161.41s | valid loss  5.74 | valid ppl   309.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   100/  663 batches | lr 4.00E-03 | ms/batch 218.16 | loss  5.83 | ppl   341.80\n",
      "| epoch   2 |   200/  663 batches | lr 4.00E-03 | ms/batch 223.33 | loss  5.74 | ppl   311.62\n",
      "| epoch   2 |   300/  663 batches | lr 4.00E-03 | ms/batch 219.42 | loss  5.72 | ppl   306.27\n",
      "| epoch   2 |   400/  663 batches | lr 4.00E-03 | ms/batch 212.56 | loss  5.64 | ppl   280.79\n",
      "| epoch   2 |   500/  663 batches | lr 4.00E-03 | ms/batch 218.60 | loss  5.61 | ppl   273.49\n",
      "| epoch   2 |   600/  663 batches | lr 4.00E-03 | ms/batch 215.94 | loss  5.52 | ppl   250.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 161.57s | valid loss  5.36 | valid ppl   213.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   100/  663 batches | lr 4.00E-03 | ms/batch 222.50 | loss  5.49 | ppl   243.07\n",
      "| epoch   3 |   200/  663 batches | lr 4.00E-03 | ms/batch 214.90 | loss  5.45 | ppl   233.60\n",
      "| epoch   3 |   300/  663 batches | lr 4.00E-03 | ms/batch 220.51 | loss  5.47 | ppl   236.36\n",
      "| epoch   3 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.17 | loss  5.40 | ppl   221.00\n",
      "| epoch   3 |   500/  663 batches | lr 4.00E-03 | ms/batch 224.27 | loss  5.37 | ppl   214.31\n",
      "| epoch   3 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.28 | loss  5.31 | ppl   202.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 161.61s | valid loss  5.21 | valid ppl   182.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   100/  663 batches | lr 4.00E-03 | ms/batch 219.89 | loss  5.32 | ppl   203.46\n",
      "| epoch   4 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.05 | loss  5.29 | ppl   197.57\n",
      "| epoch   4 |   300/  663 batches | lr 4.00E-03 | ms/batch 208.80 | loss  5.33 | ppl   206.03\n",
      "| epoch   4 |   400/  663 batches | lr 4.00E-03 | ms/batch 216.80 | loss  5.27 | ppl   194.87\n",
      "| epoch   4 |   500/  663 batches | lr 4.00E-03 | ms/batch 219.42 | loss  5.23 | ppl   186.31\n",
      "| epoch   4 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.73 | loss  5.19 | ppl   179.39\n",
      "| epoch   4 |   700/  663 batches | lr 4.00E-03 | ms/batch 215.97 | loss  5.26 | ppl   193.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 162.11s | valid loss  5.07 | valid ppl   159.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   100/  663 batches | lr 4.00E-03 | ms/batch 221.51 | loss  5.19 | ppl   179.49\n",
      "| epoch   5 |   200/  663 batches | lr 4.00E-03 | ms/batch 224.89 | loss  5.19 | ppl   178.62\n",
      "| epoch   5 |   300/  663 batches | lr 4.00E-03 | ms/batch 213.75 | loss  5.23 | ppl   187.49\n",
      "| epoch   5 |   400/  663 batches | lr 4.00E-03 | ms/batch 221.31 | loss  5.16 | ppl   173.36\n",
      "| epoch   5 |   500/  663 batches | lr 4.00E-03 | ms/batch 214.87 | loss  5.14 | ppl   169.92\n",
      "| epoch   5 |   600/  663 batches | lr 4.00E-03 | ms/batch 218.68 | loss  5.10 | ppl   163.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 161.57s | valid loss  5.01 | valid ppl   150.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.85 | loss  5.11 | ppl   164.96\n",
      "| epoch   6 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.97 | loss  5.10 | ppl   164.50\n",
      "| epoch   6 |   300/  663 batches | lr 4.00E-03 | ms/batch 213.68 | loss  5.15 | ppl   172.29\n",
      "| epoch   6 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.40 | loss  5.08 | ppl   160.57\n",
      "| epoch   6 |   500/  663 batches | lr 4.00E-03 | ms/batch 221.27 | loss  5.06 | ppl   157.19\n",
      "| epoch   6 |   600/  663 batches | lr 4.00E-03 | ms/batch 225.12 | loss  5.02 | ppl   151.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 161.72s | valid loss  4.95 | valid ppl   140.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   100/  663 batches | lr 4.00E-03 | ms/batch 221.33 | loss  5.04 | ppl   155.01\n",
      "| epoch   7 |   200/  663 batches | lr 4.00E-03 | ms/batch 216.94 | loss  5.04 | ppl   153.78\n",
      "| epoch   7 |   300/  663 batches | lr 4.00E-03 | ms/batch 222.13 | loss  5.09 | ppl   161.99\n",
      "| epoch   7 |   400/  663 batches | lr 4.00E-03 | ms/batch 219.73 | loss  5.02 | ppl   150.96\n",
      "| epoch   7 |   500/  663 batches | lr 4.00E-03 | ms/batch 223.23 | loss  4.99 | ppl   146.51\n",
      "| epoch   7 |   600/  663 batches | lr 4.00E-03 | ms/batch 222.46 | loss  4.97 | ppl   144.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 161.67s | valid loss  4.90 | valid ppl   133.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   100/  663 batches | lr 4.00E-03 | ms/batch 219.64 | loss  4.98 | ppl   144.96\n",
      "| epoch   8 |   200/  663 batches | lr 4.00E-03 | ms/batch 216.62 | loss  4.99 | ppl   146.35\n",
      "| epoch   8 |   300/  663 batches | lr 4.00E-03 | ms/batch 220.46 | loss  5.04 | ppl   154.82\n",
      "| epoch   8 |   400/  663 batches | lr 4.00E-03 | ms/batch 211.30 | loss  4.98 | ppl   145.41\n",
      "| epoch   8 |   500/  663 batches | lr 4.00E-03 | ms/batch 217.20 | loss  4.92 | ppl   137.05\n",
      "| epoch   8 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.88 | loss  4.91 | ppl   135.22\n",
      "| epoch   8 |   700/  663 batches | lr 4.00E-03 | ms/batch 214.31 | loss  5.02 | ppl   151.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 162.15s | valid loss  4.84 | valid ppl   126.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   100/  663 batches | lr 4.00E-03 | ms/batch 224.75 | loss  4.93 | ppl   137.99\n",
      "| epoch   9 |   200/  663 batches | lr 4.00E-03 | ms/batch 220.80 | loss  4.94 | ppl   139.84\n",
      "| epoch   9 |   300/  663 batches | lr 4.00E-03 | ms/batch 216.64 | loss  5.00 | ppl   148.64\n",
      "| epoch   9 |   400/  663 batches | lr 4.00E-03 | ms/batch 217.49 | loss  4.92 | ppl   137.09\n",
      "| epoch   9 |   500/  663 batches | lr 4.00E-03 | ms/batch 223.46 | loss  4.89 | ppl   133.22\n",
      "| epoch   9 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.07 | loss  4.86 | ppl   129.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 161.73s | valid loss  4.82 | valid ppl   123.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   100/  663 batches | lr 4.00E-03 | ms/batch 222.32 | loss  4.87 | ppl   130.67\n",
      "| epoch  10 |   200/  663 batches | lr 4.00E-03 | ms/batch 220.59 | loss  4.90 | ppl   133.83\n",
      "| epoch  10 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.82 | loss  4.96 | ppl   143.07\n",
      "| epoch  10 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.37 | loss  4.88 | ppl   131.13\n",
      "| epoch  10 |   500/  663 batches | lr 4.00E-03 | ms/batch 218.53 | loss  4.85 | ppl   128.33\n",
      "| epoch  10 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.37 | loss  4.85 | ppl   127.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 161.77s | valid loss  4.78 | valid ppl   118.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   100/  663 batches | lr 4.00E-03 | ms/batch 221.25 | loss  4.85 | ppl   127.92\n",
      "| epoch  11 |   200/  663 batches | lr 4.00E-03 | ms/batch 212.68 | loss  4.86 | ppl   129.55\n",
      "| epoch  11 |   300/  663 batches | lr 4.00E-03 | ms/batch 219.95 | loss  4.93 | ppl   137.90\n",
      "| epoch  11 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.71 | loss  4.85 | ppl   128.17\n",
      "| epoch  11 |   500/  663 batches | lr 4.00E-03 | ms/batch 221.16 | loss  4.81 | ppl   123.12\n",
      "| epoch  11 |   600/  663 batches | lr 4.00E-03 | ms/batch 224.94 | loss  4.79 | ppl   120.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 161.51s | valid loss  4.76 | valid ppl   116.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.33 | loss  4.82 | ppl   123.92\n",
      "| epoch  12 |   200/  663 batches | lr 4.00E-03 | ms/batch 214.27 | loss  4.83 | ppl   125.31\n",
      "| epoch  12 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.03 | loss  4.91 | ppl   135.19\n",
      "| epoch  12 |   400/  663 batches | lr 4.00E-03 | ms/batch 220.46 | loss  4.81 | ppl   123.34\n",
      "| epoch  12 |   500/  663 batches | lr 4.00E-03 | ms/batch 216.39 | loss  4.78 | ppl   119.16\n",
      "| epoch  12 |   600/  663 batches | lr 4.00E-03 | ms/batch 218.89 | loss  4.78 | ppl   119.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 161.92s | valid loss  4.73 | valid ppl   113.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   100/  663 batches | lr 4.00E-03 | ms/batch 217.53 | loss  4.78 | ppl   119.26\n",
      "| epoch  13 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.20 | loss  4.82 | ppl   123.67\n",
      "| epoch  13 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.25 | loss  4.87 | ppl   130.71\n",
      "| epoch  13 |   400/  663 batches | lr 4.00E-03 | ms/batch 215.96 | loss  4.79 | ppl   119.71\n",
      "| epoch  13 |   500/  663 batches | lr 4.00E-03 | ms/batch 218.75 | loss  4.75 | ppl   116.13\n",
      "| epoch  13 |   600/  663 batches | lr 4.00E-03 | ms/batch 219.50 | loss  4.74 | ppl   114.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 161.73s | valid loss  4.71 | valid ppl   111.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   100/  663 batches | lr 4.00E-03 | ms/batch 218.60 | loss  4.75 | ppl   115.59\n",
      "| epoch  14 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.17 | loss  4.77 | ppl   118.28\n",
      "| epoch  14 |   300/  663 batches | lr 4.00E-03 | ms/batch 220.33 | loss  4.85 | ppl   127.44\n",
      "| epoch  14 |   400/  663 batches | lr 4.00E-03 | ms/batch 219.43 | loss  4.77 | ppl   117.85\n",
      "| epoch  14 |   500/  663 batches | lr 4.00E-03 | ms/batch 229.32 | loss  4.73 | ppl   113.45\n",
      "| epoch  14 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.87 | loss  4.72 | ppl   111.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 162.13s | valid loss  4.70 | valid ppl   109.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   100/  663 batches | lr 4.00E-03 | ms/batch 225.40 | loss  4.74 | ppl   114.30\n",
      "| epoch  15 |   200/  663 batches | lr 4.00E-03 | ms/batch 217.52 | loss  4.77 | ppl   118.09\n",
      "| epoch  15 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.60 | loss  4.83 | ppl   124.74\n",
      "| epoch  15 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.54 | loss  4.75 | ppl   115.47\n",
      "| epoch  15 |   500/  663 batches | lr 4.00E-03 | ms/batch 219.67 | loss  4.71 | ppl   111.09\n",
      "| epoch  15 |   600/  663 batches | lr 4.00E-03 | ms/batch 219.67 | loss  4.70 | ppl   109.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 162.14s | valid loss  4.68 | valid ppl   107.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.44 | loss  4.72 | ppl   112.11\n",
      "| epoch  16 |   200/  663 batches | lr 4.00E-03 | ms/batch 217.86 | loss  4.74 | ppl   114.51\n",
      "| epoch  16 |   300/  663 batches | lr 4.00E-03 | ms/batch 223.62 | loss  4.80 | ppl   121.85\n",
      "| epoch  16 |   400/  663 batches | lr 4.00E-03 | ms/batch 220.72 | loss  4.73 | ppl   113.30\n",
      "| epoch  16 |   500/  663 batches | lr 4.00E-03 | ms/batch 216.20 | loss  4.69 | ppl   108.47\n",
      "| epoch  16 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.21 | loss  4.67 | ppl   107.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 162.22s | valid loss  4.67 | valid ppl   106.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   100/  663 batches | lr 4.00E-03 | ms/batch 228.05 | loss  4.68 | ppl   108.04\n",
      "| epoch  17 |   200/  663 batches | lr 4.00E-03 | ms/batch 221.33 | loss  4.75 | ppl   115.21\n",
      "| epoch  17 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.81 | loss  4.81 | ppl   122.33\n",
      "| epoch  17 |   400/  663 batches | lr 4.00E-03 | ms/batch 215.71 | loss  4.70 | ppl   110.17\n",
      "| epoch  17 |   500/  663 batches | lr 4.00E-03 | ms/batch 212.53 | loss  4.67 | ppl   107.02\n",
      "| epoch  17 |   600/  663 batches | lr 4.00E-03 | ms/batch 216.55 | loss  4.66 | ppl   105.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 161.65s | valid loss  4.66 | valid ppl   105.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   100/  663 batches | lr 4.00E-03 | ms/batch 226.35 | loss  4.68 | ppl   107.32\n",
      "| epoch  18 |   200/  663 batches | lr 4.00E-03 | ms/batch 216.57 | loss  4.72 | ppl   111.72\n",
      "| epoch  18 |   300/  663 batches | lr 4.00E-03 | ms/batch 223.16 | loss  4.78 | ppl   118.65\n",
      "| epoch  18 |   400/  663 batches | lr 4.00E-03 | ms/batch 214.36 | loss  4.70 | ppl   109.47\n",
      "| epoch  18 |   500/  663 batches | lr 4.00E-03 | ms/batch 222.25 | loss  4.66 | ppl   105.95\n",
      "| epoch  18 |   600/  663 batches | lr 4.00E-03 | ms/batch 215.36 | loss  4.65 | ppl   104.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 161.79s | valid loss  4.64 | valid ppl   104.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   100/  663 batches | lr 4.00E-03 | ms/batch 212.04 | loss  4.67 | ppl   106.53\n",
      "| epoch  19 |   200/  663 batches | lr 4.00E-03 | ms/batch 224.32 | loss  4.69 | ppl   108.68\n",
      "| epoch  19 |   300/  663 batches | lr 4.00E-03 | ms/batch 231.40 | loss  4.78 | ppl   119.02\n",
      "| epoch  19 |   400/  663 batches | lr 4.00E-03 | ms/batch 217.35 | loss  4.67 | ppl   106.77\n",
      "| epoch  19 |   500/  663 batches | lr 4.00E-03 | ms/batch 221.12 | loss  4.65 | ppl   104.08\n",
      "| epoch  19 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.97 | loss  4.65 | ppl   104.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 161.78s | valid loss  4.63 | valid ppl   102.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   100/  663 batches | lr 4.00E-03 | ms/batch 216.52 | loss  4.64 | ppl   103.68\n",
      "| epoch  20 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.07 | loss  4.69 | ppl   108.72\n",
      "| epoch  20 |   300/  663 batches | lr 4.00E-03 | ms/batch 220.32 | loss  4.75 | ppl   115.38\n",
      "| epoch  20 |   400/  663 batches | lr 4.00E-03 | ms/batch 216.92 | loss  4.67 | ppl   106.47\n",
      "| epoch  20 |   500/  663 batches | lr 4.00E-03 | ms/batch 225.65 | loss  4.61 | ppl   100.98\n",
      "| epoch  20 |   600/  663 batches | lr 4.00E-03 | ms/batch 216.52 | loss  4.61 | ppl   100.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 161.91s | valid loss  4.63 | valid ppl   102.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   100/  663 batches | lr 4.00E-03 | ms/batch 215.21 | loss  4.63 | ppl   102.25\n",
      "| epoch  21 |   200/  663 batches | lr 4.00E-03 | ms/batch 216.97 | loss  4.65 | ppl   104.61\n",
      "| epoch  21 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.26 | loss  4.74 | ppl   114.83\n",
      "| epoch  21 |   400/  663 batches | lr 4.00E-03 | ms/batch 225.84 | loss  4.66 | ppl   105.82\n",
      "| epoch  21 |   500/  663 batches | lr 4.00E-03 | ms/batch 214.72 | loss  4.61 | ppl   100.59\n",
      "| epoch  21 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.85 | loss  4.61 | ppl   100.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 161.97s | valid loss  4.62 | valid ppl   101.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   100/  663 batches | lr 4.00E-03 | ms/batch 224.87 | loss  4.61 | ppl   100.07\n",
      "| epoch  22 |   200/  663 batches | lr 4.00E-03 | ms/batch 220.89 | loss  4.67 | ppl   106.41\n",
      "| epoch  22 |   300/  663 batches | lr 4.00E-03 | ms/batch 221.97 | loss  4.73 | ppl   113.25\n",
      "| epoch  22 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.50 | loss  4.63 | ppl   102.40\n",
      "| epoch  22 |   500/  663 batches | lr 4.00E-03 | ms/batch 225.21 | loss  4.59 | ppl    98.94\n",
      "| epoch  22 |   600/  663 batches | lr 4.00E-03 | ms/batch 216.67 | loss  4.62 | ppl   101.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 161.51s | valid loss  4.61 | valid ppl   100.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |   100/  663 batches | lr 4.00E-03 | ms/batch 222.52 | loss  4.59 | ppl    98.71\n",
      "| epoch  23 |   200/  663 batches | lr 4.00E-03 | ms/batch 216.61 | loss  4.66 | ppl   105.23\n",
      "| epoch  23 |   300/  663 batches | lr 4.00E-03 | ms/batch 231.53 | loss  4.71 | ppl   111.00\n",
      "| epoch  23 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.69 | loss  4.63 | ppl   102.58\n",
      "| epoch  23 |   500/  663 batches | lr 4.00E-03 | ms/batch 221.53 | loss  4.57 | ppl    96.41\n",
      "| epoch  23 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.12 | loss  4.60 | ppl    99.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 161.70s | valid loss  4.60 | valid ppl    99.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   100/  663 batches | lr 4.00E-03 | ms/batch 222.36 | loss  4.59 | ppl    98.27\n",
      "| epoch  24 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.83 | loss  4.64 | ppl   103.80\n",
      "| epoch  24 |   300/  663 batches | lr 4.00E-03 | ms/batch 216.97 | loss  4.71 | ppl   111.01\n",
      "| epoch  24 |   400/  663 batches | lr 4.00E-03 | ms/batch 220.92 | loss  4.62 | ppl   101.32\n",
      "| epoch  24 |   500/  663 batches | lr 4.00E-03 | ms/batch 219.81 | loss  4.58 | ppl    97.48\n",
      "| epoch  24 |   600/  663 batches | lr 4.00E-03 | ms/batch 225.11 | loss  4.57 | ppl    96.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 161.93s | valid loss  4.59 | valid ppl    98.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |   100/  663 batches | lr 4.00E-03 | ms/batch 216.48 | loss  4.59 | ppl    98.18\n",
      "| epoch  25 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.97 | loss  4.60 | ppl    99.86\n",
      "| epoch  25 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.96 | loss  4.69 | ppl   109.29\n",
      "| epoch  25 |   400/  663 batches | lr 4.00E-03 | ms/batch 221.44 | loss  4.63 | ppl   102.61\n",
      "| epoch  25 |   500/  663 batches | lr 4.00E-03 | ms/batch 221.58 | loss  4.56 | ppl    95.15\n",
      "| epoch  25 |   600/  663 batches | lr 4.00E-03 | ms/batch 219.49 | loss  4.56 | ppl    95.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 162.02s | valid loss  4.59 | valid ppl    98.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.51 | loss  4.57 | ppl    96.51\n",
      "| epoch  26 |   200/  663 batches | lr 4.00E-03 | ms/batch 220.44 | loss  4.61 | ppl   100.48\n",
      "| epoch  26 |   300/  663 batches | lr 4.00E-03 | ms/batch 216.09 | loss  4.68 | ppl   107.91\n",
      "| epoch  26 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.58 | loss  4.61 | ppl   100.95\n",
      "| epoch  26 |   500/  663 batches | lr 4.00E-03 | ms/batch 219.76 | loss  4.55 | ppl    94.20\n",
      "| epoch  26 |   600/  663 batches | lr 4.00E-03 | ms/batch 219.27 | loss  4.55 | ppl    94.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 162.08s | valid loss  4.59 | valid ppl    98.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   100/  663 batches | lr 4.00E-03 | ms/batch 219.91 | loss  4.57 | ppl    96.26\n",
      "| epoch  27 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.92 | loss  4.62 | ppl   101.03\n",
      "| epoch  27 |   300/  663 batches | lr 4.00E-03 | ms/batch 222.66 | loss  4.67 | ppl   107.06\n",
      "| epoch  27 |   400/  663 batches | lr 4.00E-03 | ms/batch 214.91 | loss  4.58 | ppl    97.96\n",
      "| epoch  27 |   500/  663 batches | lr 4.00E-03 | ms/batch 225.22 | loss  4.54 | ppl    93.97\n",
      "| epoch  27 |   600/  663 batches | lr 4.00E-03 | ms/batch 222.25 | loss  4.55 | ppl    95.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 161.75s | valid loss  4.58 | valid ppl    97.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   100/  663 batches | lr 4.00E-03 | ms/batch 218.93 | loss  4.55 | ppl    94.35\n",
      "| epoch  28 |   200/  663 batches | lr 4.00E-03 | ms/batch 224.96 | loss  4.60 | ppl    99.25\n",
      "| epoch  28 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.82 | loss  4.67 | ppl   106.31\n",
      "| epoch  28 |   400/  663 batches | lr 4.00E-03 | ms/batch 219.37 | loss  4.57 | ppl    96.37\n",
      "| epoch  28 |   500/  663 batches | lr 4.00E-03 | ms/batch 222.74 | loss  4.52 | ppl    91.54\n",
      "| epoch  28 |   600/  663 batches | lr 4.00E-03 | ms/batch 214.00 | loss  4.54 | ppl    93.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 161.90s | valid loss  4.57 | valid ppl    96.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   100/  663 batches | lr 4.00E-03 | ms/batch 218.06 | loss  4.54 | ppl    94.09\n",
      "| epoch  29 |   200/  663 batches | lr 4.00E-03 | ms/batch 217.92 | loss  4.58 | ppl    97.57\n",
      "| epoch  29 |   300/  663 batches | lr 4.00E-03 | ms/batch 222.24 | loss  4.66 | ppl   105.42\n",
      "| epoch  29 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.30 | loss  4.58 | ppl    97.59\n",
      "| epoch  29 |   500/  663 batches | lr 4.00E-03 | ms/batch 211.43 | loss  4.51 | ppl    91.21\n",
      "| epoch  29 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.55 | loss  4.54 | ppl    93.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 162.12s | valid loss  4.57 | valid ppl    96.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   100/  663 batches | lr 4.00E-03 | ms/batch 230.68 | loss  4.54 | ppl    93.59\n",
      "| epoch  30 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.01 | loss  4.60 | ppl    99.57\n",
      "| epoch  30 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.99 | loss  4.65 | ppl   105.04\n",
      "| epoch  30 |   400/  663 batches | lr 4.00E-03 | ms/batch 217.08 | loss  4.56 | ppl    95.62\n",
      "| epoch  30 |   500/  663 batches | lr 4.00E-03 | ms/batch 220.17 | loss  4.52 | ppl    92.18\n",
      "| epoch  30 |   600/  663 batches | lr 4.00E-03 | ms/batch 220.32 | loss  4.53 | ppl    92.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 161.51s | valid loss  4.57 | valid ppl    96.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |   100/  663 batches | lr 4.00E-03 | ms/batch 217.81 | loss  4.53 | ppl    92.59\n",
      "| epoch  31 |   200/  663 batches | lr 4.00E-03 | ms/batch 214.45 | loss  4.56 | ppl    95.70\n",
      "| epoch  31 |   300/  663 batches | lr 4.00E-03 | ms/batch 211.87 | loss  4.64 | ppl   103.73\n",
      "| epoch  31 |   400/  663 batches | lr 4.00E-03 | ms/batch 216.57 | loss  4.57 | ppl    96.64\n",
      "| epoch  31 |   500/  663 batches | lr 4.00E-03 | ms/batch 222.50 | loss  4.50 | ppl    89.66\n",
      "| epoch  31 |   600/  663 batches | lr 4.00E-03 | ms/batch 221.09 | loss  4.53 | ppl    92.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 162.16s | valid loss  4.56 | valid ppl    95.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.09 | loss  4.51 | ppl    91.09\n",
      "| epoch  32 |   200/  663 batches | lr 4.00E-03 | ms/batch 222.74 | loss  4.57 | ppl    96.34\n",
      "| epoch  32 |   300/  663 batches | lr 4.00E-03 | ms/batch 222.04 | loss  4.64 | ppl   103.44\n",
      "| epoch  32 |   400/  663 batches | lr 4.00E-03 | ms/batch 221.53 | loss  4.55 | ppl    94.66\n",
      "| epoch  32 |   500/  663 batches | lr 4.00E-03 | ms/batch 223.03 | loss  4.49 | ppl    88.69\n",
      "| epoch  32 |   600/  663 batches | lr 4.00E-03 | ms/batch 217.70 | loss  4.52 | ppl    91.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 161.75s | valid loss  4.56 | valid ppl    95.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   100/  663 batches | lr 4.00E-03 | ms/batch 220.20 | loss  4.51 | ppl    90.74\n",
      "| epoch  33 |   200/  663 batches | lr 4.00E-03 | ms/batch 224.34 | loss  4.56 | ppl    96.05\n",
      "| epoch  33 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.36 | loss  4.63 | ppl   102.33\n",
      "| epoch  33 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.37 | loss  4.54 | ppl    93.30\n",
      "| epoch  33 |   500/  663 batches | lr 4.00E-03 | ms/batch 217.42 | loss  4.48 | ppl    88.62\n",
      "| epoch  33 |   600/  663 batches | lr 4.00E-03 | ms/batch 222.35 | loss  4.49 | ppl    89.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 161.80s | valid loss  4.55 | valid ppl    95.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |   100/  663 batches | lr 4.00E-03 | ms/batch 223.53 | loss  4.51 | ppl    90.86\n",
      "| epoch  34 |   200/  663 batches | lr 4.00E-03 | ms/batch 219.26 | loss  4.58 | ppl    97.12\n",
      "| epoch  34 |   300/  663 batches | lr 4.00E-03 | ms/batch 216.07 | loss  4.63 | ppl   102.31\n",
      "| epoch  34 |   400/  663 batches | lr 4.00E-03 | ms/batch 222.27 | loss  4.54 | ppl    93.30\n",
      "| epoch  34 |   500/  663 batches | lr 4.00E-03 | ms/batch 222.86 | loss  4.49 | ppl    89.02\n",
      "| epoch  34 |   600/  663 batches | lr 4.00E-03 | ms/batch 219.66 | loss  4.49 | ppl    89.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 161.98s | valid loss  4.55 | valid ppl    94.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   100/  663 batches | lr 4.00E-03 | ms/batch 225.22 | loss  4.50 | ppl    89.67\n",
      "| epoch  35 |   200/  663 batches | lr 4.00E-03 | ms/batch 221.63 | loss  4.56 | ppl    95.14\n",
      "| epoch  35 |   300/  663 batches | lr 4.00E-03 | ms/batch 216.34 | loss  4.63 | ppl   102.22\n",
      "| epoch  35 |   400/  663 batches | lr 4.00E-03 | ms/batch 218.77 | loss  4.53 | ppl    92.38\n",
      "| epoch  35 |   500/  663 batches | lr 4.00E-03 | ms/batch 220.51 | loss  4.48 | ppl    87.87\n",
      "| epoch  35 |   600/  663 batches | lr 4.00E-03 | ms/batch 226.99 | loss  4.49 | ppl    89.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 161.73s | valid loss  4.55 | valid ppl    94.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   100/  663 batches | lr 4.00E-03 | ms/batch 215.40 | loss  4.50 | ppl    90.12\n",
      "| epoch  36 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.27 | loss  4.53 | ppl    92.39\n",
      "| epoch  36 |   300/  663 batches | lr 4.00E-03 | ms/batch 218.01 | loss  4.62 | ppl   101.45\n",
      "| epoch  36 |   400/  663 batches | lr 4.00E-03 | ms/batch 223.90 | loss  4.53 | ppl    92.53\n",
      "| epoch  36 |   500/  663 batches | lr 4.00E-03 | ms/batch 218.83 | loss  4.48 | ppl    87.86\n",
      "| epoch  36 |   600/  663 batches | lr 4.00E-03 | ms/batch 216.16 | loss  4.48 | ppl    88.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 161.95s | valid loss  4.54 | valid ppl    93.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |   100/  663 batches | lr 4.00E-03 | ms/batch 224.80 | loss  4.47 | ppl    87.09\n",
      "| epoch  37 |   200/  663 batches | lr 4.00E-03 | ms/batch 218.00 | loss  4.55 | ppl    94.23\n",
      "| epoch  37 |   300/  663 batches | lr 4.00E-03 | ms/batch 217.55 | loss  4.60 | ppl    99.96\n",
      "| epoch  37 |   400/  663 batches | lr 4.00E-03 | ms/batch 221.29 | loss  4.52 | ppl    91.64\n",
      "| epoch  37 |   500/  663 batches | lr 4.00E-03 | ms/batch 222.60 | loss  4.47 | ppl    87.25\n",
      "| epoch  37 |   600/  663 batches | lr 4.00E-03 | ms/batch 215.46 | loss  4.47 | ppl    87.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 161.77s | valid loss  4.55 | valid ppl    94.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   100/  663 batches | lr 1.00E-03 | ms/batch 224.44 | loss  4.46 | ppl    86.75\n",
      "| epoch  38 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.06 | loss  4.50 | ppl    90.19\n",
      "| epoch  38 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.54 | loss  4.54 | ppl    93.25\n",
      "| epoch  38 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.37 | loss  4.44 | ppl    84.80\n",
      "| epoch  38 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.56 | loss  4.35 | ppl    77.53\n",
      "| epoch  38 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.37 | loss  4.36 | ppl    77.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 162.28s | valid loss  4.51 | valid ppl    90.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   100/  663 batches | lr 1.00E-03 | ms/batch 224.37 | loss  4.38 | ppl    80.09\n",
      "| epoch  39 |   200/  663 batches | lr 1.00E-03 | ms/batch 212.98 | loss  4.45 | ppl    85.58\n",
      "| epoch  39 |   300/  663 batches | lr 1.00E-03 | ms/batch 215.44 | loss  4.51 | ppl    90.87\n",
      "| epoch  39 |   400/  663 batches | lr 1.00E-03 | ms/batch 215.08 | loss  4.41 | ppl    82.37\n",
      "| epoch  39 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.04 | loss  4.32 | ppl    75.33\n",
      "| epoch  39 |   600/  663 batches | lr 1.00E-03 | ms/batch 211.10 | loss  4.32 | ppl    75.23\n",
      "| epoch  39 |   700/  663 batches | lr 1.00E-03 | ms/batch 219.20 | loss  4.41 | ppl    82.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 162.10s | valid loss  4.50 | valid ppl    90.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   100/  663 batches | lr 1.00E-03 | ms/batch 214.61 | loss  4.37 | ppl    79.19\n",
      "| epoch  40 |   200/  663 batches | lr 1.00E-03 | ms/batch 212.56 | loss  4.39 | ppl    80.24\n",
      "| epoch  40 |   300/  663 batches | lr 1.00E-03 | ms/batch 215.83 | loss  4.48 | ppl    88.62\n",
      "| epoch  40 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.76 | loss  4.39 | ppl    80.86\n",
      "| epoch  40 |   500/  663 batches | lr 1.00E-03 | ms/batch 223.88 | loss  4.30 | ppl    74.03\n",
      "| epoch  40 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.93 | loss  4.30 | ppl    74.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 162.05s | valid loss  4.50 | valid ppl    89.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |   100/  663 batches | lr 1.00E-03 | ms/batch 217.72 | loss  4.34 | ppl    76.89\n",
      "| epoch  41 |   200/  663 batches | lr 1.00E-03 | ms/batch 215.50 | loss  4.39 | ppl    80.24\n",
      "| epoch  41 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.08 | loss  4.46 | ppl    86.84\n",
      "| epoch  41 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.55 | loss  4.37 | ppl    79.06\n",
      "| epoch  41 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.99 | loss  4.29 | ppl    73.00\n",
      "| epoch  41 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.46 | loss  4.29 | ppl    73.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 161.99s | valid loss  4.49 | valid ppl    89.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   100/  663 batches | lr 1.00E-03 | ms/batch 228.36 | loss  4.32 | ppl    75.53\n",
      "| epoch  42 |   200/  663 batches | lr 1.00E-03 | ms/batch 224.40 | loss  4.41 | ppl    81.91\n",
      "| epoch  42 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.79 | loss  4.46 | ppl    86.15\n",
      "| epoch  42 |   400/  663 batches | lr 1.00E-03 | ms/batch 215.25 | loss  4.33 | ppl    76.24\n",
      "| epoch  42 |   500/  663 batches | lr 1.00E-03 | ms/batch 215.89 | loss  4.27 | ppl    71.79\n",
      "| epoch  42 |   600/  663 batches | lr 1.00E-03 | ms/batch 226.19 | loss  4.30 | ppl    73.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 161.82s | valid loss  4.49 | valid ppl    89.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   100/  663 batches | lr 1.00E-03 | ms/batch 225.68 | loss  4.31 | ppl    74.57\n",
      "| epoch  43 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.64 | loss  4.37 | ppl    79.19\n",
      "| epoch  43 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.09 | loss  4.44 | ppl    85.07\n",
      "| epoch  43 |   400/  663 batches | lr 1.00E-03 | ms/batch 221.32 | loss  4.33 | ppl    75.60\n",
      "| epoch  43 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.01 | loss  4.26 | ppl    70.51\n",
      "| epoch  43 |   600/  663 batches | lr 1.00E-03 | ms/batch 221.46 | loss  4.28 | ppl    72.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 161.67s | valid loss  4.49 | valid ppl    89.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   100/  663 batches | lr 1.00E-03 | ms/batch 218.77 | loss  4.32 | ppl    74.84\n",
      "| epoch  44 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.59 | loss  4.35 | ppl    77.38\n",
      "| epoch  44 |   300/  663 batches | lr 1.00E-03 | ms/batch 220.74 | loss  4.42 | ppl    83.12\n",
      "| epoch  44 |   400/  663 batches | lr 1.00E-03 | ms/batch 221.16 | loss  4.31 | ppl    74.29\n",
      "| epoch  44 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.72 | loss  4.26 | ppl    70.78\n",
      "| epoch  44 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.68 | loss  4.27 | ppl    71.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 161.77s | valid loss  4.49 | valid ppl    89.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.37 | loss  4.29 | ppl    73.00\n",
      "| epoch  45 |   200/  663 batches | lr 1.00E-03 | ms/batch 227.75 | loss  4.35 | ppl    77.38\n",
      "| epoch  45 |   300/  663 batches | lr 1.00E-03 | ms/batch 225.43 | loss  4.41 | ppl    82.67\n",
      "| epoch  45 |   400/  663 batches | lr 1.00E-03 | ms/batch 217.12 | loss  4.30 | ppl    73.90\n",
      "| epoch  45 |   500/  663 batches | lr 1.00E-03 | ms/batch 216.65 | loss  4.23 | ppl    68.83\n",
      "| epoch  45 |   600/  663 batches | lr 1.00E-03 | ms/batch 212.95 | loss  4.25 | ppl    70.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 161.66s | valid loss  4.49 | valid ppl    89.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   100/  663 batches | lr 2.50E-04 | ms/batch 223.01 | loss  4.29 | ppl    72.62\n",
      "| epoch  46 |   200/  663 batches | lr 2.50E-04 | ms/batch 216.54 | loss  4.34 | ppl    76.45\n",
      "| epoch  46 |   300/  663 batches | lr 2.50E-04 | ms/batch 218.23 | loss  4.39 | ppl    80.78\n",
      "| epoch  46 |   400/  663 batches | lr 2.50E-04 | ms/batch 219.22 | loss  4.28 | ppl    72.29\n",
      "| epoch  46 |   500/  663 batches | lr 2.50E-04 | ms/batch 213.67 | loss  4.21 | ppl    67.55\n",
      "| epoch  46 |   600/  663 batches | lr 2.50E-04 | ms/batch 219.53 | loss  4.20 | ppl    66.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 162.06s | valid loss  4.49 | valid ppl    88.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   100/  663 batches | lr 2.50E-04 | ms/batch 217.89 | loss  4.26 | ppl    70.98\n",
      "| epoch  47 |   200/  663 batches | lr 2.50E-04 | ms/batch 215.01 | loss  4.31 | ppl    74.33\n",
      "| epoch  47 |   300/  663 batches | lr 2.50E-04 | ms/batch 221.09 | loss  4.38 | ppl    80.01\n",
      "| epoch  47 |   400/  663 batches | lr 2.50E-04 | ms/batch 214.29 | loss  4.28 | ppl    72.01\n",
      "| epoch  47 |   500/  663 batches | lr 2.50E-04 | ms/batch 217.94 | loss  4.19 | ppl    66.33\n",
      "| epoch  47 |   600/  663 batches | lr 2.50E-04 | ms/batch 223.01 | loss  4.20 | ppl    66.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 161.96s | valid loss  4.49 | valid ppl    88.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   100/  663 batches | lr 2.50E-04 | ms/batch 225.45 | loss  4.25 | ppl    69.84\n",
      "| epoch  48 |   200/  663 batches | lr 2.50E-04 | ms/batch 220.15 | loss  4.31 | ppl    74.12\n",
      "| epoch  48 |   300/  663 batches | lr 2.50E-04 | ms/batch 218.90 | loss  4.37 | ppl    79.26\n",
      "| epoch  48 |   400/  663 batches | lr 2.50E-04 | ms/batch 217.19 | loss  4.26 | ppl    70.68\n",
      "| epoch  48 |   500/  663 batches | lr 2.50E-04 | ms/batch 219.75 | loss  4.19 | ppl    66.17\n",
      "| epoch  48 |   600/  663 batches | lr 2.50E-04 | ms/batch 218.17 | loss  4.20 | ppl    66.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 162.21s | valid loss  4.49 | valid ppl    88.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |   100/  663 batches | lr 2.50E-04 | ms/batch 226.59 | loss  4.24 | ppl    69.66\n",
      "| epoch  49 |   200/  663 batches | lr 2.50E-04 | ms/batch 227.75 | loss  4.30 | ppl    73.57\n",
      "| epoch  49 |   300/  663 batches | lr 2.50E-04 | ms/batch 226.44 | loss  4.36 | ppl    77.94\n",
      "| epoch  49 |   400/  663 batches | lr 2.50E-04 | ms/batch 221.52 | loss  4.25 | ppl    70.27\n",
      "| epoch  49 |   500/  663 batches | lr 2.50E-04 | ms/batch 216.94 | loss  4.17 | ppl    64.51\n",
      "| epoch  49 |   600/  663 batches | lr 2.50E-04 | ms/batch 221.01 | loss  4.21 | ppl    67.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 161.63s | valid loss  4.49 | valid ppl    88.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   100/  663 batches | lr 2.50E-04 | ms/batch 224.09 | loss  4.24 | ppl    69.41\n",
      "| epoch  50 |   200/  663 batches | lr 2.50E-04 | ms/batch 224.00 | loss  4.27 | ppl    71.39\n",
      "| epoch  50 |   300/  663 batches | lr 2.50E-04 | ms/batch 217.22 | loss  4.33 | ppl    76.28\n",
      "| epoch  50 |   400/  663 batches | lr 2.50E-04 | ms/batch 224.92 | loss  4.24 | ppl    69.15\n",
      "| epoch  50 |   500/  663 batches | lr 2.50E-04 | ms/batch 215.57 | loss  4.17 | ppl    64.63\n",
      "| epoch  50 |   600/  663 batches | lr 2.50E-04 | ms/batch 222.27 | loss  4.19 | ppl    66.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 162.21s | valid loss  4.49 | valid ppl    88.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |   100/  663 batches | lr 2.50E-04 | ms/batch 221.56 | loss  4.22 | ppl    67.80\n",
      "| epoch  51 |   200/  663 batches | lr 2.50E-04 | ms/batch 226.49 | loss  4.28 | ppl    72.35\n",
      "| epoch  51 |   300/  663 batches | lr 2.50E-04 | ms/batch 226.21 | loss  4.34 | ppl    76.56\n",
      "| epoch  51 |   400/  663 batches | lr 2.50E-04 | ms/batch 213.53 | loss  4.23 | ppl    68.86\n",
      "| epoch  51 |   500/  663 batches | lr 2.50E-04 | ms/batch 216.45 | loss  4.16 | ppl    64.11\n",
      "| epoch  51 |   600/  663 batches | lr 2.50E-04 | ms/batch 213.10 | loss  4.16 | ppl    64.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 161.87s | valid loss  4.49 | valid ppl    88.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |   100/  663 batches | lr 2.50E-04 | ms/batch 218.01 | loss  4.24 | ppl    69.69\n",
      "| epoch  52 |   200/  663 batches | lr 2.50E-04 | ms/batch 220.17 | loss  4.26 | ppl    70.82\n",
      "| epoch  52 |   300/  663 batches | lr 2.50E-04 | ms/batch 223.45 | loss  4.33 | ppl    75.78\n",
      "| epoch  52 |   400/  663 batches | lr 2.50E-04 | ms/batch 221.78 | loss  4.22 | ppl    67.70\n",
      "| epoch  52 |   500/  663 batches | lr 2.50E-04 | ms/batch 219.58 | loss  4.17 | ppl    64.54\n",
      "| epoch  52 |   600/  663 batches | lr 2.50E-04 | ms/batch 221.21 | loss  4.17 | ppl    64.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 161.94s | valid loss  4.49 | valid ppl    88.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |   100/  663 batches | lr 2.50E-04 | ms/batch 217.24 | loss  4.21 | ppl    67.50\n",
      "| epoch  53 |   200/  663 batches | lr 2.50E-04 | ms/batch 220.86 | loss  4.24 | ppl    69.67\n",
      "| epoch  53 |   300/  663 batches | lr 2.50E-04 | ms/batch 213.76 | loss  4.33 | ppl    75.71\n",
      "| epoch  53 |   400/  663 batches | lr 2.50E-04 | ms/batch 217.22 | loss  4.23 | ppl    68.62\n",
      "| epoch  53 |   500/  663 batches | lr 2.50E-04 | ms/batch 223.54 | loss  4.15 | ppl    63.48\n",
      "| epoch  53 |   600/  663 batches | lr 2.50E-04 | ms/batch 216.93 | loss  4.16 | ppl    64.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 162.10s | valid loss  4.49 | valid ppl    88.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |   100/  663 batches | lr 6.25E-05 | ms/batch 223.37 | loss  4.21 | ppl    67.22\n",
      "| epoch  54 |   200/  663 batches | lr 6.25E-05 | ms/batch 222.44 | loss  4.27 | ppl    71.22\n",
      "| epoch  54 |   300/  663 batches | lr 6.25E-05 | ms/batch 219.26 | loss  4.32 | ppl    75.19\n",
      "| epoch  54 |   400/  663 batches | lr 6.25E-05 | ms/batch 218.50 | loss  4.21 | ppl    67.32\n",
      "| epoch  54 |   500/  663 batches | lr 6.25E-05 | ms/batch 225.53 | loss  4.14 | ppl    62.89\n",
      "| epoch  54 |   600/  663 batches | lr 6.25E-05 | ms/batch 217.24 | loss  4.14 | ppl    62.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 161.96s | valid loss  4.49 | valid ppl    88.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |   100/  663 batches | lr 1.56E-05 | ms/batch 221.11 | loss  4.21 | ppl    67.16\n",
      "| epoch  55 |   200/  663 batches | lr 1.56E-05 | ms/batch 226.11 | loss  4.24 | ppl    69.42\n",
      "| epoch  55 |   300/  663 batches | lr 1.56E-05 | ms/batch 217.93 | loss  4.32 | ppl    75.08\n",
      "| epoch  55 |   400/  663 batches | lr 1.56E-05 | ms/batch 223.55 | loss  4.20 | ppl    66.82\n",
      "| epoch  55 |   500/  663 batches | lr 1.56E-05 | ms/batch 219.69 | loss  4.13 | ppl    62.47\n",
      "| epoch  55 |   600/  663 batches | lr 1.56E-05 | ms/batch 222.64 | loss  4.15 | ppl    63.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 162.16s | valid loss  4.48 | valid ppl    88.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |   100/  663 batches | lr 1.56E-05 | ms/batch 223.07 | loss  4.19 | ppl    66.31\n",
      "| epoch  56 |   200/  663 batches | lr 1.56E-05 | ms/batch 216.86 | loss  4.25 | ppl    70.15\n",
      "| epoch  56 |   300/  663 batches | lr 1.56E-05 | ms/batch 213.43 | loss  4.31 | ppl    74.43\n",
      "| epoch  56 |   400/  663 batches | lr 1.56E-05 | ms/batch 213.13 | loss  4.21 | ppl    67.60\n",
      "| epoch  56 |   500/  663 batches | lr 1.56E-05 | ms/batch 213.05 | loss  4.13 | ppl    62.12\n",
      "| epoch  56 |   600/  663 batches | lr 1.56E-05 | ms/batch 221.47 | loss  4.14 | ppl    62.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 162.25s | valid loss  4.48 | valid ppl    88.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |   100/  663 batches | lr 1.56E-05 | ms/batch 218.56 | loss  4.20 | ppl    66.71\n",
      "| epoch  57 |   200/  663 batches | lr 1.56E-05 | ms/batch 222.57 | loss  4.24 | ppl    69.12\n",
      "| epoch  57 |   300/  663 batches | lr 1.56E-05 | ms/batch 221.57 | loss  4.32 | ppl    74.83\n",
      "| epoch  57 |   400/  663 batches | lr 1.56E-05 | ms/batch 217.86 | loss  4.21 | ppl    67.33\n",
      "| epoch  57 |   500/  663 batches | lr 1.56E-05 | ms/batch 220.03 | loss  4.15 | ppl    63.47\n",
      "| epoch  57 |   600/  663 batches | lr 1.56E-05 | ms/batch 223.95 | loss  4.14 | ppl    63.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 161.80s | valid loss  4.48 | valid ppl    88.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |   100/  663 batches | lr 3.91E-06 | ms/batch 221.51 | loss  4.21 | ppl    67.48\n",
      "| epoch  58 |   200/  663 batches | lr 3.91E-06 | ms/batch 216.94 | loss  4.24 | ppl    69.19\n",
      "| epoch  58 |   300/  663 batches | lr 3.91E-06 | ms/batch 220.87 | loss  4.32 | ppl    75.22\n",
      "| epoch  58 |   400/  663 batches | lr 3.91E-06 | ms/batch 219.66 | loss  4.20 | ppl    66.86\n",
      "| epoch  58 |   500/  663 batches | lr 3.91E-06 | ms/batch 220.02 | loss  4.14 | ppl    62.89\n",
      "| epoch  58 |   600/  663 batches | lr 3.91E-06 | ms/batch 215.88 | loss  4.14 | ppl    62.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 162.18s | valid loss  4.48 | valid ppl    88.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |   100/  663 batches | lr 3.91E-06 | ms/batch 223.90 | loss  4.20 | ppl    66.97\n",
      "| epoch  59 |   200/  663 batches | lr 3.91E-06 | ms/batch 219.93 | loss  4.24 | ppl    69.47\n",
      "| epoch  59 |   300/  663 batches | lr 3.91E-06 | ms/batch 217.58 | loss  4.31 | ppl    74.55\n",
      "| epoch  59 |   400/  663 batches | lr 3.91E-06 | ms/batch 217.56 | loss  4.20 | ppl    66.87\n",
      "| epoch  59 |   500/  663 batches | lr 3.91E-06 | ms/batch 218.29 | loss  4.14 | ppl    62.87\n",
      "| epoch  59 |   600/  663 batches | lr 3.91E-06 | ms/batch 219.80 | loss  4.14 | ppl    62.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 162.03s | valid loss  4.48 | valid ppl    88.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |   100/  663 batches | lr 3.91E-06 | ms/batch 220.46 | loss  4.20 | ppl    66.37\n",
      "| epoch  60 |   200/  663 batches | lr 3.91E-06 | ms/batch 225.55 | loss  4.22 | ppl    68.21\n",
      "| epoch  60 |   300/  663 batches | lr 3.91E-06 | ms/batch 225.84 | loss  4.31 | ppl    74.44\n",
      "| epoch  60 |   400/  663 batches | lr 3.91E-06 | ms/batch 221.47 | loss  4.20 | ppl    66.77\n",
      "| epoch  60 |   500/  663 batches | lr 3.91E-06 | ms/batch 216.77 | loss  4.12 | ppl    61.56\n",
      "| epoch  60 |   600/  663 batches | lr 3.91E-06 | ms/batch 220.82 | loss  4.15 | ppl    63.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 162.03s | valid loss  4.48 | valid ppl    88.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 |   100/  663 batches | lr 3.91E-06 | ms/batch 215.81 | loss  4.20 | ppl    66.59\n",
      "| epoch  61 |   200/  663 batches | lr 3.91E-06 | ms/batch 221.16 | loss  4.23 | ppl    68.48\n",
      "| epoch  61 |   300/  663 batches | lr 3.91E-06 | ms/batch 217.85 | loss  4.31 | ppl    74.61\n",
      "| epoch  61 |   400/  663 batches | lr 3.91E-06 | ms/batch 218.72 | loss  4.22 | ppl    67.75\n",
      "| epoch  61 |   500/  663 batches | lr 3.91E-06 | ms/batch 217.52 | loss  4.13 | ppl    62.15\n",
      "| epoch  61 |   600/  663 batches | lr 3.91E-06 | ms/batch 216.54 | loss  4.14 | ppl    62.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 162.13s | valid loss  4.48 | valid ppl    88.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |   100/  663 batches | lr 3.91E-06 | ms/batch 220.64 | loss  4.19 | ppl    66.03\n",
      "| epoch  62 |   200/  663 batches | lr 3.91E-06 | ms/batch 225.44 | loss  4.23 | ppl    68.98\n",
      "| epoch  62 |   300/  663 batches | lr 3.91E-06 | ms/batch 221.06 | loss  4.31 | ppl    74.32\n",
      "| epoch  62 |   400/  663 batches | lr 3.91E-06 | ms/batch 215.47 | loss  4.22 | ppl    67.95\n",
      "| epoch  62 |   500/  663 batches | lr 3.91E-06 | ms/batch 216.70 | loss  4.14 | ppl    62.78\n",
      "| epoch  62 |   600/  663 batches | lr 3.91E-06 | ms/batch 214.91 | loss  4.13 | ppl    62.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 162.21s | valid loss  4.48 | valid ppl    88.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1e20\n",
    "try:\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(valid_data, args.eval_batch_size)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "            epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        if val_loss < best_val_loss:\n",
    "            with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            lr *= LR_ANNEALING_RATE\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  4.45 | test ppl    85.52\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss = evaluate(test_data, args.test_batch_size)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
