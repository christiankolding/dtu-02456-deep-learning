{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import WD_LSTM\n",
    "from data import Corpus\n",
    "from randomize_bptt import get_bptt_sequence_lengths\n",
    "from helpers import Config, repackage_hidden, batchify, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATA = '/floyd/home/ptb/'\n",
    "CUDA = True\n",
    "LOG_INTERVAL = 100\n",
    "LR_ANNEALING_RATE = 0.5\n",
    "CONFIG_NAME = 'language_model_base'\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "args = Config(CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "train_data = batchify(corpus.train, args.batch_size, device)\n",
    "valid_data = batchify(corpus.valid, args.eval_batch_size, device)\n",
    "test_data = batchify(corpus.test, args.test_batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WD_LSTM(\n",
       "  (variational_dropout): VariationalDropout()\n",
       "  (encoder): Embedding(10000, 400)\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDrop(\n",
       "      (module): LSTM(400, 1150)\n",
       "    )\n",
       "    (1): WeightDrop(\n",
       "      (module): LSTM(1150, 1150)\n",
       "    )\n",
       "    (2): WeightDrop(\n",
       "      (module): LSTM(1150, 400)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=400, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WD_LSTM(\n",
    "    ntoken=ntokens, \n",
    "    ninp=args.emsize,\n",
    "    nhid=args.nhid, \n",
    "    nlayers=args.nlayers, \n",
    "    dropout=args.dropout,\n",
    "    dropout_h=args.dropout_h,\n",
    "    dropout_i=args.dropout_i,\n",
    "    dropout_e=args.dropout_e,\n",
    "    weight_drop=args.weight_drop, \n",
    "    weight_tying=args.weight_tying\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = args.lr\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source, batch_size):\n",
    "    model.eval()  # disable dropout\n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, args.bptt_seq_len):\n",
    "            data, targets = get_batch(data_source, i, args.bptt_seq_len)\n",
    "            output, hidden, _, _ = model(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_tar_regularization_loss(outputs, dropped_outputs):\n",
    "    reg_loss = 0\n",
    "    for i in range(len(dropped_outputs[-1])):\n",
    "        reg_loss += args.alpha * dropped_outputs[-1][i].pow(2).mean()\n",
    "        if i >= 1:\n",
    "            reg_loss += args.beta * (outputs[-1][i] - outputs[-1][i - 1]).pow(2).mean()\n",
    "    return reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    for batch, (i, seq_len, lr_scale) in enumerate(get_bptt_sequence_lengths(\n",
    "        train_data.size(0), \n",
    "        args.bptt_seq_len, \n",
    "        args.bptt_random_scaling, \n",
    "        args.bptt_p, \n",
    "        args.bptt_s, \n",
    "        args.bptt_min_len\n",
    "    )):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr * lr_scale\n",
    "        data, targets = get_batch(train_data, i, seq_len)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden, outputs, dropped_outputs = model(data, hidden)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        unregularized_loss = criterion(output_flat, targets)\n",
    "        regularized_loss = unregularized_loss + ar_tar_regularization_loss(outputs, dropped_outputs)\n",
    "        regularized_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        total_loss += unregularized_loss.item()\n",
    "        if batch % LOG_INTERVAL == 0 and batch > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:3.2E} | ms/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // args.bptt_seq_len, lr,\n",
    "                elapsed * 1000 / LOG_INTERVAL, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py:477: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/  663 batches | lr 1.00E-03 | ms/batch 223.30 | loss  7.06 | ppl  1166.48\n",
      "| epoch   1 |   200/  663 batches | lr 1.00E-03 | ms/batch 218.10 | loss  6.41 | ppl   608.74\n",
      "| epoch   1 |   300/  663 batches | lr 1.00E-03 | ms/batch 215.07 | loss  6.29 | ppl   538.62\n",
      "| epoch   1 |   400/  663 batches | lr 1.00E-03 | ms/batch 223.60 | loss  6.14 | ppl   466.11\n",
      "| epoch   1 |   500/  663 batches | lr 1.00E-03 | ms/batch 216.42 | loss  6.03 | ppl   417.02\n",
      "| epoch   1 |   600/  663 batches | lr 1.00E-03 | ms/batch 217.27 | loss  5.91 | ppl   367.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 161.54s | valid loss  5.70 | valid ppl   298.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   100/  663 batches | lr 1.00E-03 | ms/batch 218.25 | loss  5.80 | ppl   331.77\n",
      "| epoch   2 |   200/  663 batches | lr 1.00E-03 | ms/batch 224.08 | loss  5.71 | ppl   303.14\n",
      "| epoch   2 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.89 | loss  5.71 | ppl   300.55\n",
      "| epoch   2 |   400/  663 batches | lr 1.00E-03 | ms/batch 212.53 | loss  5.62 | ppl   274.79\n",
      "| epoch   2 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.09 | loss  5.59 | ppl   268.08\n",
      "| epoch   2 |   600/  663 batches | lr 1.00E-03 | ms/batch 216.68 | loss  5.50 | ppl   244.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 161.96s | valid loss  5.34 | valid ppl   209.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   100/  663 batches | lr 1.00E-03 | ms/batch 222.33 | loss  5.47 | ppl   238.00\n",
      "| epoch   3 |   200/  663 batches | lr 1.00E-03 | ms/batch 215.16 | loss  5.43 | ppl   228.81\n",
      "| epoch   3 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.71 | loss  5.44 | ppl   231.24\n",
      "| epoch   3 |   400/  663 batches | lr 1.00E-03 | ms/batch 217.35 | loss  5.37 | ppl   215.31\n",
      "| epoch   3 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.56 | loss  5.33 | ppl   206.99\n",
      "| epoch   3 |   600/  663 batches | lr 1.00E-03 | ms/batch 221.29 | loss  5.28 | ppl   195.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 161.64s | valid loss  5.14 | valid ppl   170.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.40 | loss  5.27 | ppl   194.23\n",
      "| epoch   4 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.54 | loss  5.24 | ppl   188.79\n",
      "| epoch   4 |   300/  663 batches | lr 1.00E-03 | ms/batch 208.72 | loss  5.28 | ppl   196.85\n",
      "| epoch   4 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.15 | loss  5.22 | ppl   184.18\n",
      "| epoch   4 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.61 | loss  5.16 | ppl   174.59\n",
      "| epoch   4 |   600/  663 batches | lr 1.00E-03 | ms/batch 217.94 | loss  5.13 | ppl   168.52\n",
      "| epoch   4 |   700/  663 batches | lr 1.00E-03 | ms/batch 216.02 | loss  5.20 | ppl   181.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 162.30s | valid loss  5.00 | valid ppl   147.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.71 | loss  5.12 | ppl   166.75\n",
      "| epoch   5 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.15 | loss  5.11 | ppl   166.29\n",
      "| epoch   5 |   300/  663 batches | lr 1.00E-03 | ms/batch 213.74 | loss  5.17 | ppl   175.22\n",
      "| epoch   5 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.94 | loss  5.08 | ppl   160.16\n",
      "| epoch   5 |   500/  663 batches | lr 1.00E-03 | ms/batch 214.08 | loss  5.04 | ppl   155.04\n",
      "| epoch   5 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.28 | loss  5.01 | ppl   149.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 161.77s | valid loss  4.90 | valid ppl   133.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.21 | loss  5.00 | ppl   148.83\n",
      "| epoch   6 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.07 | loss  5.01 | ppl   149.27\n",
      "| epoch   6 |   300/  663 batches | lr 1.00E-03 | ms/batch 214.37 | loss  5.05 | ppl   156.75\n",
      "| epoch   6 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.53 | loss  4.98 | ppl   144.77\n",
      "| epoch   6 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.83 | loss  4.94 | ppl   139.70\n",
      "| epoch   6 |   600/  663 batches | lr 1.00E-03 | ms/batch 225.45 | loss  4.91 | ppl   135.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 162.11s | valid loss  4.81 | valid ppl   122.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.46 | loss  4.92 | ppl   136.34\n",
      "| epoch   7 |   200/  663 batches | lr 1.00E-03 | ms/batch 216.57 | loss  4.92 | ppl   136.39\n",
      "| epoch   7 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.10 | loss  4.97 | ppl   144.19\n",
      "| epoch   7 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.04 | loss  4.89 | ppl   132.60\n",
      "| epoch   7 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.93 | loss  4.85 | ppl   127.23\n",
      "| epoch   7 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.40 | loss  4.83 | ppl   125.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 161.56s | valid loss  4.74 | valid ppl   114.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.37 | loss  4.83 | ppl   124.59\n",
      "| epoch   8 |   200/  663 batches | lr 1.00E-03 | ms/batch 216.97 | loss  4.84 | ppl   127.09\n",
      "| epoch   8 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.34 | loss  4.91 | ppl   135.60\n",
      "| epoch   8 |   400/  663 batches | lr 1.00E-03 | ms/batch 211.77 | loss  4.83 | ppl   124.90\n",
      "| epoch   8 |   500/  663 batches | lr 1.00E-03 | ms/batch 217.34 | loss  4.76 | ppl   116.63\n",
      "| epoch   8 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.07 | loss  4.75 | ppl   115.79\n",
      "| epoch   8 |   700/  663 batches | lr 1.00E-03 | ms/batch 214.69 | loss  4.86 | ppl   128.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 162.59s | valid loss  4.69 | valid ppl   108.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   100/  663 batches | lr 1.00E-03 | ms/batch 224.81 | loss  4.75 | ppl   115.91\n",
      "| epoch   9 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.40 | loss  4.78 | ppl   119.58\n",
      "| epoch   9 |   300/  663 batches | lr 1.00E-03 | ms/batch 216.56 | loss  4.85 | ppl   127.28\n",
      "| epoch   9 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.01 | loss  4.75 | ppl   115.83\n",
      "| epoch   9 |   500/  663 batches | lr 1.00E-03 | ms/batch 223.49 | loss  4.71 | ppl   111.08\n",
      "| epoch   9 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.35 | loss  4.69 | ppl   108.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 161.84s | valid loss  4.64 | valid ppl   103.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   100/  663 batches | lr 1.00E-03 | ms/batch 223.14 | loss  4.69 | ppl   108.74\n",
      "| epoch  10 |   200/  663 batches | lr 1.00E-03 | ms/batch 220.69 | loss  4.72 | ppl   112.61\n",
      "| epoch  10 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.48 | loss  4.79 | ppl   120.36\n",
      "| epoch  10 |   400/  663 batches | lr 1.00E-03 | ms/batch 224.11 | loss  4.69 | ppl   108.83\n",
      "| epoch  10 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.82 | loss  4.66 | ppl   105.35\n",
      "| epoch  10 |   600/  663 batches | lr 1.00E-03 | ms/batch 221.97 | loss  4.66 | ppl   105.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 162.26s | valid loss  4.60 | valid ppl    99.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.35 | loss  4.65 | ppl   104.27\n",
      "| epoch  11 |   200/  663 batches | lr 1.00E-03 | ms/batch 213.30 | loss  4.68 | ppl   107.41\n",
      "| epoch  11 |   300/  663 batches | lr 1.00E-03 | ms/batch 220.26 | loss  4.75 | ppl   115.13\n",
      "| epoch  11 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.02 | loss  4.66 | ppl   105.47\n",
      "| epoch  11 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.33 | loss  4.60 | ppl    99.67\n",
      "| epoch  11 |   600/  663 batches | lr 1.00E-03 | ms/batch 225.94 | loss  4.59 | ppl    98.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 162.00s | valid loss  4.57 | valid ppl    96.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.74 | loss  4.60 | ppl    99.72\n",
      "| epoch  12 |   200/  663 batches | lr 1.00E-03 | ms/batch 215.52 | loss  4.63 | ppl   102.03\n",
      "| epoch  12 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.98 | loss  4.71 | ppl   110.65\n",
      "| epoch  12 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.87 | loss  4.61 | ppl   100.24\n",
      "| epoch  12 |   500/  663 batches | lr 1.00E-03 | ms/batch 216.96 | loss  4.55 | ppl    94.97\n",
      "| epoch  12 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.16 | loss  4.56 | ppl    95.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 162.52s | valid loss  4.54 | valid ppl    93.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   100/  663 batches | lr 1.00E-03 | ms/batch 217.90 | loss  4.55 | ppl    95.03\n",
      "| epoch  13 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.63 | loss  4.60 | ppl    99.19\n",
      "| epoch  13 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.27 | loss  4.66 | ppl   105.98\n",
      "| epoch  13 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.27 | loss  4.56 | ppl    95.70\n",
      "| epoch  13 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.25 | loss  4.51 | ppl    90.99\n",
      "| epoch  13 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.73 | loss  4.51 | ppl    91.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 162.24s | valid loss  4.51 | valid ppl    91.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.31 | loss  4.52 | ppl    91.48\n",
      "| epoch  14 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.50 | loss  4.54 | ppl    93.99\n",
      "| epoch  14 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.58 | loss  4.63 | ppl   102.24\n",
      "| epoch  14 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.79 | loss  4.53 | ppl    93.04\n",
      "| epoch  14 |   500/  663 batches | lr 1.00E-03 | ms/batch 229.51 | loss  4.48 | ppl    88.01\n",
      "| epoch  14 |   600/  663 batches | lr 1.00E-03 | ms/batch 216.64 | loss  4.48 | ppl    87.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 162.54s | valid loss  4.49 | valid ppl    89.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   100/  663 batches | lr 1.00E-03 | ms/batch 225.14 | loss  4.49 | ppl    89.17\n",
      "| epoch  15 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.98 | loss  4.53 | ppl    92.75\n",
      "| epoch  15 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.51 | loss  4.59 | ppl    98.57\n",
      "| epoch  15 |   400/  663 batches | lr 1.00E-03 | ms/batch 223.86 | loss  4.50 | ppl    90.21\n",
      "| epoch  15 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.94 | loss  4.45 | ppl    85.23\n",
      "| epoch  15 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.70 | loss  4.45 | ppl    85.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 162.18s | valid loss  4.47 | valid ppl    87.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.67 | loss  4.46 | ppl    86.30\n",
      "| epoch  16 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.11 | loss  4.49 | ppl    89.12\n",
      "| epoch  16 |   300/  663 batches | lr 1.00E-03 | ms/batch 225.01 | loss  4.55 | ppl    94.72\n",
      "| epoch  16 |   400/  663 batches | lr 1.00E-03 | ms/batch 221.97 | loss  4.47 | ppl    87.59\n",
      "| epoch  16 |   500/  663 batches | lr 1.00E-03 | ms/batch 217.24 | loss  4.41 | ppl    82.55\n",
      "| epoch  16 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.34 | loss  4.41 | ppl    82.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 163.08s | valid loss  4.46 | valid ppl    86.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   100/  663 batches | lr 1.00E-03 | ms/batch 229.09 | loss  4.42 | ppl    82.81\n",
      "| epoch  17 |   200/  663 batches | lr 1.00E-03 | ms/batch 222.13 | loss  4.49 | ppl    88.98\n",
      "| epoch  17 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.67 | loss  4.55 | ppl    94.49\n",
      "| epoch  17 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.57 | loss  4.44 | ppl    84.47\n",
      "| epoch  17 |   500/  663 batches | lr 1.00E-03 | ms/batch 213.38 | loss  4.39 | ppl    80.69\n",
      "| epoch  17 |   600/  663 batches | lr 1.00E-03 | ms/batch 217.56 | loss  4.39 | ppl    80.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 162.33s | valid loss  4.45 | valid ppl    85.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.44 | loss  4.40 | ppl    81.17\n",
      "| epoch  18 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.42 | loss  4.45 | ppl    85.46\n",
      "| epoch  18 |   300/  663 batches | lr 1.00E-03 | ms/batch 224.50 | loss  4.51 | ppl    90.73\n",
      "| epoch  18 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.03 | loss  4.42 | ppl    82.97\n",
      "| epoch  18 |   500/  663 batches | lr 1.00E-03 | ms/batch 223.92 | loss  4.37 | ppl    78.82\n",
      "| epoch  18 |   600/  663 batches | lr 1.00E-03 | ms/batch 216.39 | loss  4.37 | ppl    79.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 162.69s | valid loss  4.43 | valid ppl    84.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   100/  663 batches | lr 1.00E-03 | ms/batch 213.37 | loss  4.38 | ppl    79.75\n",
      "| epoch  19 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.26 | loss  4.41 | ppl    82.34\n",
      "| epoch  19 |   300/  663 batches | lr 1.00E-03 | ms/batch 231.89 | loss  4.50 | ppl    90.40\n",
      "| epoch  19 |   400/  663 batches | lr 1.00E-03 | ms/batch 217.85 | loss  4.38 | ppl    80.18\n",
      "| epoch  19 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.84 | loss  4.34 | ppl    76.85\n",
      "| epoch  19 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.07 | loss  4.36 | ppl    78.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 162.38s | valid loss  4.42 | valid ppl    82.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   100/  663 batches | lr 1.00E-03 | ms/batch 218.12 | loss  4.35 | ppl    77.15\n",
      "| epoch  20 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.80 | loss  4.40 | ppl    81.50\n",
      "| epoch  20 |   300/  663 batches | lr 1.00E-03 | ms/batch 220.33 | loss  4.47 | ppl    87.52\n",
      "| epoch  20 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.10 | loss  4.37 | ppl    78.97\n",
      "| epoch  20 |   500/  663 batches | lr 1.00E-03 | ms/batch 226.83 | loss  4.31 | ppl    74.60\n",
      "| epoch  20 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.42 | loss  4.32 | ppl    74.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 162.96s | valid loss  4.40 | valid ppl    81.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   100/  663 batches | lr 1.00E-03 | ms/batch 216.21 | loss  4.32 | ppl    75.26\n",
      "| epoch  21 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.42 | loss  4.35 | ppl    77.63\n",
      "| epoch  21 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.48 | loss  4.45 | ppl    85.65\n",
      "| epoch  21 |   400/  663 batches | lr 1.00E-03 | ms/batch 226.91 | loss  4.36 | ppl    78.30\n",
      "| epoch  21 |   500/  663 batches | lr 1.00E-03 | ms/batch 216.07 | loss  4.29 | ppl    73.02\n",
      "| epoch  21 |   600/  663 batches | lr 1.00E-03 | ms/batch 223.04 | loss  4.30 | ppl    73.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 162.79s | valid loss  4.40 | valid ppl    81.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.19 | loss  4.29 | ppl    73.10\n",
      "| epoch  22 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.49 | loss  4.36 | ppl    78.52\n",
      "| epoch  22 |   300/  663 batches | lr 1.00E-03 | ms/batch 223.03 | loss  4.43 | ppl    83.82\n",
      "| epoch  22 |   400/  663 batches | lr 1.00E-03 | ms/batch 224.31 | loss  4.32 | ppl    75.14\n",
      "| epoch  22 |   500/  663 batches | lr 1.00E-03 | ms/batch 226.12 | loss  4.27 | ppl    71.30\n",
      "| epoch  22 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.68 | loss  4.31 | ppl    74.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 162.40s | valid loss  4.38 | valid ppl    80.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |   100/  663 batches | lr 1.00E-03 | ms/batch 224.09 | loss  4.27 | ppl    71.54\n",
      "| epoch  23 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.96 | loss  4.34 | ppl    76.35\n",
      "| epoch  23 |   300/  663 batches | lr 1.00E-03 | ms/batch 231.72 | loss  4.40 | ppl    81.35\n",
      "| epoch  23 |   400/  663 batches | lr 1.00E-03 | ms/batch 224.57 | loss  4.31 | ppl    74.52\n",
      "| epoch  23 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.23 | loss  4.23 | ppl    68.87\n",
      "| epoch  23 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.56 | loss  4.27 | ppl    71.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 162.53s | valid loss  4.38 | valid ppl    79.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   100/  663 batches | lr 1.00E-03 | ms/batch 223.58 | loss  4.26 | ppl    71.05\n",
      "| epoch  24 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.46 | loss  4.32 | ppl    75.48\n",
      "| epoch  24 |   300/  663 batches | lr 1.00E-03 | ms/batch 217.48 | loss  4.40 | ppl    81.14\n",
      "| epoch  24 |   400/  663 batches | lr 1.00E-03 | ms/batch 221.94 | loss  4.29 | ppl    73.15\n",
      "| epoch  24 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.90 | loss  4.24 | ppl    69.44\n",
      "| epoch  24 |   600/  663 batches | lr 1.00E-03 | ms/batch 226.21 | loss  4.24 | ppl    69.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 162.65s | valid loss  4.37 | valid ppl    79.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |   100/  663 batches | lr 1.00E-03 | ms/batch 218.15 | loss  4.25 | ppl    70.32\n",
      "| epoch  25 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.43 | loss  4.27 | ppl    71.67\n",
      "| epoch  25 |   300/  663 batches | lr 1.00E-03 | ms/batch 220.55 | loss  4.37 | ppl    79.06\n",
      "| epoch  25 |   400/  663 batches | lr 1.00E-03 | ms/batch 222.02 | loss  4.29 | ppl    73.18\n",
      "| epoch  25 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.26 | loss  4.20 | ppl    67.00\n",
      "| epoch  25 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.49 | loss  4.22 | ppl    68.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 163.02s | valid loss  4.36 | valid ppl    78.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   100/  663 batches | lr 1.00E-03 | ms/batch 222.14 | loss  4.23 | ppl    68.52\n",
      "| epoch  26 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.27 | loss  4.27 | ppl    71.82\n",
      "| epoch  26 |   300/  663 batches | lr 1.00E-03 | ms/batch 216.99 | loss  4.35 | ppl    77.70\n",
      "| epoch  26 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.32 | loss  4.27 | ppl    71.46\n",
      "| epoch  26 |   500/  663 batches | lr 1.00E-03 | ms/batch 220.27 | loss  4.20 | ppl    66.43\n",
      "| epoch  26 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.12 | loss  4.20 | ppl    66.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 162.91s | valid loss  4.35 | valid ppl    77.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.97 | loss  4.22 | ppl    67.81\n",
      "| epoch  27 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.63 | loss  4.27 | ppl    71.60\n",
      "| epoch  27 |   300/  663 batches | lr 1.00E-03 | ms/batch 224.43 | loss  4.34 | ppl    76.55\n",
      "| epoch  27 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.52 | loss  4.23 | ppl    68.81\n",
      "| epoch  27 |   500/  663 batches | lr 1.00E-03 | ms/batch 226.77 | loss  4.19 | ppl    65.70\n",
      "| epoch  27 |   600/  663 batches | lr 1.00E-03 | ms/batch 223.49 | loss  4.20 | ppl    66.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 163.00s | valid loss  4.35 | valid ppl    77.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.64 | loss  4.19 | ppl    66.30\n",
      "| epoch  28 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.24 | loss  4.24 | ppl    69.54\n",
      "| epoch  28 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.27 | loss  4.32 | ppl    75.40\n",
      "| epoch  28 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.44 | loss  4.22 | ppl    67.72\n",
      "| epoch  28 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.10 | loss  4.15 | ppl    63.24\n",
      "| epoch  28 |   600/  663 batches | lr 1.00E-03 | ms/batch 215.36 | loss  4.17 | ppl    64.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 162.61s | valid loss  4.34 | valid ppl    76.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.50 | loss  4.18 | ppl    65.28\n",
      "| epoch  29 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.43 | loss  4.23 | ppl    68.43\n",
      "| epoch  29 |   300/  663 batches | lr 1.00E-03 | ms/batch 223.25 | loss  4.31 | ppl    74.55\n",
      "| epoch  29 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.46 | loss  4.22 | ppl    67.76\n",
      "| epoch  29 |   500/  663 batches | lr 1.00E-03 | ms/batch 213.60 | loss  4.13 | ppl    62.35\n",
      "| epoch  29 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.30 | loss  4.17 | ppl    64.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 163.33s | valid loss  4.33 | valid ppl    76.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   100/  663 batches | lr 1.00E-03 | ms/batch 231.68 | loss  4.17 | ppl    64.60\n",
      "| epoch  30 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.94 | loss  4.24 | ppl    69.30\n",
      "| epoch  30 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.12 | loss  4.30 | ppl    73.60\n",
      "| epoch  30 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.15 | loss  4.19 | ppl    66.11\n",
      "| epoch  30 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.99 | loss  4.15 | ppl    63.14\n",
      "| epoch  30 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.22 | loss  4.16 | ppl    63.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 162.75s | valid loss  4.33 | valid ppl    75.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |   100/  663 batches | lr 1.00E-03 | ms/batch 218.90 | loss  4.15 | ppl    63.60\n",
      "| epoch  31 |   200/  663 batches | lr 1.00E-03 | ms/batch 215.56 | loss  4.19 | ppl    66.25\n",
      "| epoch  31 |   300/  663 batches | lr 1.00E-03 | ms/batch 213.48 | loss  4.28 | ppl    72.34\n",
      "| epoch  31 |   400/  663 batches | lr 1.00E-03 | ms/batch 217.60 | loss  4.19 | ppl    66.07\n",
      "| epoch  31 |   500/  663 batches | lr 1.00E-03 | ms/batch 223.91 | loss  4.11 | ppl    61.16\n",
      "| epoch  31 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.91 | loss  4.14 | ppl    62.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 163.26s | valid loss  4.32 | valid ppl    75.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   100/  663 batches | lr 1.00E-03 | ms/batch 221.56 | loss  4.14 | ppl    62.51\n",
      "| epoch  32 |   200/  663 batches | lr 1.00E-03 | ms/batch 223.91 | loss  4.19 | ppl    66.22\n",
      "| epoch  32 |   300/  663 batches | lr 1.00E-03 | ms/batch 223.54 | loss  4.27 | ppl    71.58\n",
      "| epoch  32 |   400/  663 batches | lr 1.00E-03 | ms/batch 222.89 | loss  4.17 | ppl    64.52\n",
      "| epoch  32 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.86 | loss  4.10 | ppl    60.08\n",
      "| epoch  32 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.24 | loss  4.13 | ppl    62.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 162.85s | valid loss  4.32 | valid ppl    74.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   100/  663 batches | lr 1.00E-03 | ms/batch 222.34 | loss  4.12 | ppl    61.64\n",
      "| epoch  33 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.38 | loss  4.18 | ppl    65.49\n",
      "| epoch  33 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.39 | loss  4.25 | ppl    70.29\n",
      "| epoch  33 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.04 | loss  4.15 | ppl    63.21\n",
      "| epoch  33 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.31 | loss  4.09 | ppl    59.49\n",
      "| epoch  33 |   600/  663 batches | lr 1.00E-03 | ms/batch 223.92 | loss  4.10 | ppl    60.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 163.09s | valid loss  4.31 | valid ppl    74.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |   100/  663 batches | lr 1.00E-03 | ms/batch 225.34 | loss  4.12 | ppl    61.73\n",
      "| epoch  34 |   200/  663 batches | lr 1.00E-03 | ms/batch 220.46 | loss  4.19 | ppl    66.00\n",
      "| epoch  34 |   300/  663 batches | lr 1.00E-03 | ms/batch 217.68 | loss  4.25 | ppl    70.17\n",
      "| epoch  34 |   400/  663 batches | lr 1.00E-03 | ms/batch 224.53 | loss  4.15 | ppl    63.13\n",
      "| epoch  34 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.61 | loss  4.09 | ppl    59.90\n",
      "| epoch  34 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.93 | loss  4.09 | ppl    59.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 163.29s | valid loss  4.30 | valid ppl    73.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.36 | loss  4.10 | ppl    60.34\n",
      "| epoch  35 |   200/  663 batches | lr 1.00E-03 | ms/batch 222.21 | loss  4.16 | ppl    64.14\n",
      "| epoch  35 |   300/  663 batches | lr 1.00E-03 | ms/batch 217.26 | loss  4.24 | ppl    69.58\n",
      "| epoch  35 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.60 | loss  4.13 | ppl    62.20\n",
      "| epoch  35 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.68 | loss  4.07 | ppl    58.77\n",
      "| epoch  35 |   600/  663 batches | lr 1.00E-03 | ms/batch 228.67 | loss  4.09 | ppl    59.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 162.70s | valid loss  4.30 | valid ppl    73.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   100/  663 batches | lr 1.00E-03 | ms/batch 217.34 | loss  4.11 | ppl    60.68\n",
      "| epoch  36 |   200/  663 batches | lr 1.00E-03 | ms/batch 220.45 | loss  4.13 | ppl    62.34\n",
      "| epoch  36 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.70 | loss  4.23 | ppl    68.79\n",
      "| epoch  36 |   400/  663 batches | lr 1.00E-03 | ms/batch 225.72 | loss  4.13 | ppl    61.91\n",
      "| epoch  36 |   500/  663 batches | lr 1.00E-03 | ms/batch 221.04 | loss  4.07 | ppl    58.39\n",
      "| epoch  36 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.01 | loss  4.08 | ppl    59.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 163.37s | valid loss  4.30 | valid ppl    73.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.33 | loss  4.06 | ppl    58.23\n",
      "| epoch  37 |   200/  663 batches | lr 1.00E-03 | ms/batch 219.78 | loss  4.15 | ppl    63.26\n",
      "| epoch  37 |   300/  663 batches | lr 1.00E-03 | ms/batch 218.56 | loss  4.22 | ppl    67.83\n",
      "| epoch  37 |   400/  663 batches | lr 1.00E-03 | ms/batch 222.72 | loss  4.11 | ppl    61.02\n",
      "| epoch  37 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.34 | loss  4.05 | ppl    57.56\n",
      "| epoch  37 |   600/  663 batches | lr 1.00E-03 | ms/batch 216.55 | loss  4.06 | ppl    58.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 162.90s | valid loss  4.29 | valid ppl    73.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.40 | loss  4.07 | ppl    58.46\n",
      "| epoch  38 |   200/  663 batches | lr 1.00E-03 | ms/batch 220.47 | loss  4.13 | ppl    62.41\n",
      "| epoch  38 |   300/  663 batches | lr 1.00E-03 | ms/batch 222.34 | loss  4.19 | ppl    66.19\n",
      "| epoch  38 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.85 | loss  4.11 | ppl    60.76\n",
      "| epoch  38 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.47 | loss  4.04 | ppl    56.68\n",
      "| epoch  38 |   600/  663 batches | lr 1.00E-03 | ms/batch 219.33 | loss  4.07 | ppl    58.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 163.36s | valid loss  4.29 | valid ppl    72.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   100/  663 batches | lr 1.00E-03 | ms/batch 226.23 | loss  4.04 | ppl    56.84\n",
      "| epoch  39 |   200/  663 batches | lr 1.00E-03 | ms/batch 214.14 | loss  4.12 | ppl    61.72\n",
      "| epoch  39 |   300/  663 batches | lr 1.00E-03 | ms/batch 216.95 | loss  4.19 | ppl    66.28\n",
      "| epoch  39 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.75 | loss  4.10 | ppl    60.58\n",
      "| epoch  39 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.69 | loss  4.03 | ppl    56.24\n",
      "| epoch  39 |   600/  663 batches | lr 1.00E-03 | ms/batch 212.60 | loss  4.04 | ppl    56.93\n",
      "| epoch  39 |   700/  663 batches | lr 1.00E-03 | ms/batch 219.99 | loss  4.16 | ppl    63.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 163.25s | valid loss  4.29 | valid ppl    72.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   100/  663 batches | lr 1.00E-03 | ms/batch 216.47 | loss  4.05 | ppl    57.60\n",
      "| epoch  40 |   200/  663 batches | lr 1.00E-03 | ms/batch 214.75 | loss  4.07 | ppl    58.65\n",
      "| epoch  40 |   300/  663 batches | lr 1.00E-03 | ms/batch 217.21 | loss  4.18 | ppl    65.24\n",
      "| epoch  40 |   400/  663 batches | lr 1.00E-03 | ms/batch 222.64 | loss  4.09 | ppl    59.81\n",
      "| epoch  40 |   500/  663 batches | lr 1.00E-03 | ms/batch 226.15 | loss  4.02 | ppl    55.78\n",
      "| epoch  40 |   600/  663 batches | lr 1.00E-03 | ms/batch 224.59 | loss  4.04 | ppl    56.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 163.43s | valid loss  4.28 | valid ppl    72.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.35 | loss  4.03 | ppl    56.47\n",
      "| epoch  41 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.16 | loss  4.09 | ppl    59.53\n",
      "| epoch  41 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.45 | loss  4.17 | ppl    64.92\n",
      "| epoch  41 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.47 | loss  4.08 | ppl    59.24\n",
      "| epoch  41 |   500/  663 batches | lr 1.00E-03 | ms/batch 224.92 | loss  4.01 | ppl    55.14\n",
      "| epoch  41 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.05 | loss  4.02 | ppl    55.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 163.26s | valid loss  4.28 | valid ppl    72.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   100/  663 batches | lr 1.00E-03 | ms/batch 228.76 | loss  4.03 | ppl    56.19\n",
      "| epoch  42 |   200/  663 batches | lr 1.00E-03 | ms/batch 226.09 | loss  4.11 | ppl    60.86\n",
      "| epoch  42 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.69 | loss  4.17 | ppl    64.69\n",
      "| epoch  42 |   400/  663 batches | lr 1.00E-03 | ms/batch 217.28 | loss  4.06 | ppl    57.76\n",
      "| epoch  42 |   500/  663 batches | lr 1.00E-03 | ms/batch 217.73 | loss  4.01 | ppl    54.90\n",
      "| epoch  42 |   600/  663 batches | lr 1.00E-03 | ms/batch 228.40 | loss  4.03 | ppl    56.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 163.09s | valid loss  4.28 | valid ppl    71.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   100/  663 batches | lr 1.00E-03 | ms/batch 227.23 | loss  4.02 | ppl    55.70\n",
      "| epoch  43 |   200/  663 batches | lr 1.00E-03 | ms/batch 223.19 | loss  4.08 | ppl    59.33\n",
      "| epoch  43 |   300/  663 batches | lr 1.00E-03 | ms/batch 223.05 | loss  4.16 | ppl    64.06\n",
      "| epoch  43 |   400/  663 batches | lr 1.00E-03 | ms/batch 223.35 | loss  4.05 | ppl    57.41\n",
      "| epoch  43 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.73 | loss  3.99 | ppl    53.97\n",
      "| epoch  43 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.79 | loss  4.02 | ppl    55.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 162.91s | valid loss  4.27 | valid ppl    71.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   100/  663 batches | lr 1.00E-03 | ms/batch 220.04 | loss  4.02 | ppl    55.92\n",
      "| epoch  44 |   200/  663 batches | lr 1.00E-03 | ms/batch 226.71 | loss  4.06 | ppl    58.15\n",
      "| epoch  44 |   300/  663 batches | lr 1.00E-03 | ms/batch 221.98 | loss  4.15 | ppl    63.14\n",
      "| epoch  44 |   400/  663 batches | lr 1.00E-03 | ms/batch 222.29 | loss  4.04 | ppl    56.76\n",
      "| epoch  44 |   500/  663 batches | lr 1.00E-03 | ms/batch 226.32 | loss  3.99 | ppl    54.28\n",
      "| epoch  44 |   600/  663 batches | lr 1.00E-03 | ms/batch 221.57 | loss  4.00 | ppl    54.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 162.86s | valid loss  4.27 | valid ppl    71.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |   100/  663 batches | lr 1.00E-03 | ms/batch 222.36 | loss  4.01 | ppl    54.98\n",
      "| epoch  45 |   200/  663 batches | lr 1.00E-03 | ms/batch 229.41 | loss  4.08 | ppl    58.90\n",
      "| epoch  45 |   300/  663 batches | lr 1.00E-03 | ms/batch 227.04 | loss  4.15 | ppl    63.12\n",
      "| epoch  45 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.99 | loss  4.04 | ppl    56.84\n",
      "| epoch  45 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.94 | loss  3.97 | ppl    53.09\n",
      "| epoch  45 |   600/  663 batches | lr 1.00E-03 | ms/batch 214.49 | loss  4.00 | ppl    54.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 163.02s | valid loss  4.27 | valid ppl    71.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   100/  663 batches | lr 1.00E-03 | ms/batch 224.46 | loss  4.01 | ppl    54.96\n",
      "| epoch  46 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.99 | loss  4.07 | ppl    58.45\n",
      "| epoch  46 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.52 | loss  4.13 | ppl    62.47\n",
      "| epoch  46 |   400/  663 batches | lr 1.00E-03 | ms/batch 220.77 | loss  4.03 | ppl    56.33\n",
      "| epoch  46 |   500/  663 batches | lr 1.00E-03 | ms/batch 214.68 | loss  3.98 | ppl    53.42\n",
      "| epoch  46 |   600/  663 batches | lr 1.00E-03 | ms/batch 221.28 | loss  3.99 | ppl    53.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 163.20s | valid loss  4.26 | valid ppl    71.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.68 | loss  4.00 | ppl    54.50\n",
      "| epoch  47 |   200/  663 batches | lr 1.00E-03 | ms/batch 217.61 | loss  4.04 | ppl    56.98\n",
      "| epoch  47 |   300/  663 batches | lr 1.00E-03 | ms/batch 222.82 | loss  4.13 | ppl    62.00\n",
      "| epoch  47 |   400/  663 batches | lr 1.00E-03 | ms/batch 216.35 | loss  4.03 | ppl    56.34\n",
      "| epoch  47 |   500/  663 batches | lr 1.00E-03 | ms/batch 219.46 | loss  3.96 | ppl    52.52\n",
      "| epoch  47 |   600/  663 batches | lr 1.00E-03 | ms/batch 224.61 | loss  3.97 | ppl    53.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 163.34s | valid loss  4.26 | valid ppl    70.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   100/  663 batches | lr 1.00E-03 | ms/batch 225.69 | loss  3.98 | ppl    53.73\n",
      "| epoch  48 |   200/  663 batches | lr 1.00E-03 | ms/batch 220.12 | loss  4.04 | ppl    57.07\n",
      "| epoch  48 |   300/  663 batches | lr 1.00E-03 | ms/batch 219.77 | loss  4.12 | ppl    61.70\n",
      "| epoch  48 |   400/  663 batches | lr 1.00E-03 | ms/batch 218.37 | loss  4.01 | ppl    55.32\n",
      "| epoch  48 |   500/  663 batches | lr 1.00E-03 | ms/batch 222.14 | loss  3.96 | ppl    52.51\n",
      "| epoch  48 |   600/  663 batches | lr 1.00E-03 | ms/batch 220.23 | loss  3.97 | ppl    53.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 163.23s | valid loss  4.26 | valid ppl    70.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |   100/  663 batches | lr 1.00E-03 | ms/batch 228.64 | loss  3.98 | ppl    53.60\n",
      "| epoch  49 |   200/  663 batches | lr 1.00E-03 | ms/batch 229.81 | loss  4.04 | ppl    56.61\n",
      "| epoch  49 |   300/  663 batches | lr 1.00E-03 | ms/batch 227.94 | loss  4.11 | ppl    60.71\n",
      "| epoch  49 |   400/  663 batches | lr 1.00E-03 | ms/batch 223.28 | loss  4.01 | ppl    55.05\n",
      "| epoch  49 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.66 | loss  3.94 | ppl    51.37\n",
      "| epoch  49 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.65 | loss  4.00 | ppl    54.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 162.99s | valid loss  4.26 | valid ppl    70.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   100/  663 batches | lr 1.00E-03 | ms/batch 225.82 | loss  3.98 | ppl    53.33\n",
      "| epoch  50 |   200/  663 batches | lr 1.00E-03 | ms/batch 225.69 | loss  4.00 | ppl    54.75\n",
      "| epoch  50 |   300/  663 batches | lr 1.00E-03 | ms/batch 217.80 | loss  4.08 | ppl    59.18\n",
      "| epoch  50 |   400/  663 batches | lr 1.00E-03 | ms/batch 224.82 | loss  3.99 | ppl    54.30\n",
      "| epoch  50 |   500/  663 batches | lr 1.00E-03 | ms/batch 215.92 | loss  3.94 | ppl    51.28\n",
      "| epoch  50 |   600/  663 batches | lr 1.00E-03 | ms/batch 223.76 | loss  3.98 | ppl    53.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 162.96s | valid loss  4.26 | valid ppl    70.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |   100/  663 batches | lr 1.00E-03 | ms/batch 223.53 | loss  3.95 | ppl    52.08\n",
      "| epoch  51 |   200/  663 batches | lr 1.00E-03 | ms/batch 227.96 | loss  4.02 | ppl    55.72\n",
      "| epoch  51 |   300/  663 batches | lr 1.00E-03 | ms/batch 229.17 | loss  4.08 | ppl    59.20\n",
      "| epoch  51 |   400/  663 batches | lr 1.00E-03 | ms/batch 215.32 | loss  3.99 | ppl    53.86\n",
      "| epoch  51 |   500/  663 batches | lr 1.00E-03 | ms/batch 218.14 | loss  3.93 | ppl    51.04\n",
      "| epoch  51 |   600/  663 batches | lr 1.00E-03 | ms/batch 215.65 | loss  3.93 | ppl    51.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 163.47s | valid loss  4.25 | valid ppl    70.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.70 | loss  3.98 | ppl    53.32\n",
      "| epoch  52 |   200/  663 batches | lr 1.00E-03 | ms/batch 221.42 | loss  4.00 | ppl    54.57\n",
      "| epoch  52 |   300/  663 batches | lr 1.00E-03 | ms/batch 225.29 | loss  4.07 | ppl    58.63\n",
      "| epoch  52 |   400/  663 batches | lr 1.00E-03 | ms/batch 223.05 | loss  3.98 | ppl    53.44\n",
      "| epoch  52 |   500/  663 batches | lr 1.00E-03 | ms/batch 220.62 | loss  3.94 | ppl    51.17\n",
      "| epoch  52 |   600/  663 batches | lr 1.00E-03 | ms/batch 222.14 | loss  3.94 | ppl    51.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 163.04s | valid loss  4.25 | valid ppl    69.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |   100/  663 batches | lr 1.00E-03 | ms/batch 219.11 | loss  3.95 | ppl    52.08\n",
      "| epoch  53 |   200/  663 batches | lr 1.00E-03 | ms/batch 222.62 | loss  3.98 | ppl    53.67\n",
      "| epoch  53 |   300/  663 batches | lr 1.00E-03 | ms/batch 215.69 | loss  4.08 | ppl    59.12\n",
      "| epoch  53 |   400/  663 batches | lr 1.00E-03 | ms/batch 219.41 | loss  3.99 | ppl    53.97\n",
      "| epoch  53 |   500/  663 batches | lr 1.00E-03 | ms/batch 225.80 | loss  3.93 | ppl    50.75\n",
      "| epoch  53 |   600/  663 batches | lr 1.00E-03 | ms/batch 218.19 | loss  3.94 | ppl    51.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 163.54s | valid loss  4.25 | valid ppl    70.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |   100/  663 batches | lr 5.00E-04 | ms/batch 225.82 | loss  3.94 | ppl    51.64\n",
      "| epoch  54 |   200/  663 batches | lr 5.00E-04 | ms/batch 224.66 | loss  3.99 | ppl    54.11\n",
      "| epoch  54 |   300/  663 batches | lr 5.00E-04 | ms/batch 221.64 | loss  4.04 | ppl    57.03\n",
      "| epoch  54 |   400/  663 batches | lr 5.00E-04 | ms/batch 220.27 | loss  3.94 | ppl    51.24\n",
      "| epoch  54 |   500/  663 batches | lr 5.00E-04 | ms/batch 227.10 | loss  3.87 | ppl    48.08\n",
      "| epoch  54 |   600/  663 batches | lr 5.00E-04 | ms/batch 218.68 | loss  3.87 | ppl    47.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 163.34s | valid loss  4.24 | valid ppl    69.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |   100/  663 batches | lr 5.00E-04 | ms/batch 221.89 | loss  3.91 | ppl    49.96\n",
      "| epoch  55 |   200/  663 batches | lr 5.00E-04 | ms/batch 227.53 | loss  3.95 | ppl    51.77\n",
      "| epoch  55 |   300/  663 batches | lr 5.00E-04 | ms/batch 219.11 | loss  4.02 | ppl    55.92\n",
      "| epoch  55 |   400/  663 batches | lr 5.00E-04 | ms/batch 225.82 | loss  3.91 | ppl    49.90\n",
      "| epoch  55 |   500/  663 batches | lr 5.00E-04 | ms/batch 221.58 | loss  3.85 | ppl    47.12\n",
      "| epoch  55 |   600/  663 batches | lr 5.00E-04 | ms/batch 224.51 | loss  3.87 | ppl    48.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 163.34s | valid loss  4.24 | valid ppl    69.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |   100/  663 batches | lr 5.00E-04 | ms/batch 224.82 | loss  3.89 | ppl    48.78\n",
      "| epoch  56 |   200/  663 batches | lr 5.00E-04 | ms/batch 218.89 | loss  3.94 | ppl    51.21\n",
      "| epoch  56 |   300/  663 batches | lr 5.00E-04 | ms/batch 215.39 | loss  4.01 | ppl    55.21\n",
      "| epoch  56 |   400/  663 batches | lr 5.00E-04 | ms/batch 214.83 | loss  3.92 | ppl    50.23\n",
      "| epoch  56 |   500/  663 batches | lr 5.00E-04 | ms/batch 214.72 | loss  3.84 | ppl    46.36\n",
      "| epoch  56 |   600/  663 batches | lr 5.00E-04 | ms/batch 223.02 | loss  3.85 | ppl    46.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 163.52s | valid loss  4.24 | valid ppl    69.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |   100/  663 batches | lr 2.50E-04 | ms/batch 220.08 | loss  3.88 | ppl    48.30\n",
      "| epoch  57 |   200/  663 batches | lr 2.50E-04 | ms/batch 224.06 | loss  3.92 | ppl    50.21\n",
      "| epoch  57 |   300/  663 batches | lr 2.50E-04 | ms/batch 223.56 | loss  3.99 | ppl    54.04\n",
      "| epoch  57 |   400/  663 batches | lr 2.50E-04 | ms/batch 219.43 | loss  3.88 | ppl    48.23\n",
      "| epoch  57 |   500/  663 batches | lr 2.50E-04 | ms/batch 221.57 | loss  3.83 | ppl    45.86\n",
      "| epoch  57 |   600/  663 batches | lr 2.50E-04 | ms/batch 225.42 | loss  3.82 | ppl    45.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 163.07s | valid loss  4.24 | valid ppl    69.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |   100/  663 batches | lr 2.50E-04 | ms/batch 222.14 | loss  3.87 | ppl    48.11\n",
      "| epoch  58 |   200/  663 batches | lr 2.50E-04 | ms/batch 218.68 | loss  3.90 | ppl    49.21\n",
      "| epoch  58 |   300/  663 batches | lr 2.50E-04 | ms/batch 223.27 | loss  3.98 | ppl    53.61\n",
      "| epoch  58 |   400/  663 batches | lr 2.50E-04 | ms/batch 221.59 | loss  3.86 | ppl    47.70\n",
      "| epoch  58 |   500/  663 batches | lr 2.50E-04 | ms/batch 222.02 | loss  3.80 | ppl    44.81\n",
      "| epoch  58 |   600/  663 batches | lr 2.50E-04 | ms/batch 217.05 | loss  3.81 | ppl    45.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 163.36s | valid loss  4.23 | valid ppl    69.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |   100/  663 batches | lr 2.50E-04 | ms/batch 226.19 | loss  3.85 | ppl    46.91\n",
      "| epoch  59 |   200/  663 batches | lr 2.50E-04 | ms/batch 221.38 | loss  3.89 | ppl    48.95\n",
      "| epoch  59 |   300/  663 batches | lr 2.50E-04 | ms/batch 219.11 | loss  3.97 | ppl    52.74\n",
      "| epoch  59 |   400/  663 batches | lr 2.50E-04 | ms/batch 219.28 | loss  3.86 | ppl    47.45\n",
      "| epoch  59 |   500/  663 batches | lr 2.50E-04 | ms/batch 219.88 | loss  3.80 | ppl    44.73\n",
      "| epoch  59 |   600/  663 batches | lr 2.50E-04 | ms/batch 220.91 | loss  3.80 | ppl    44.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 163.21s | valid loss  4.23 | valid ppl    68.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |   100/  663 batches | lr 2.50E-04 | ms/batch 222.49 | loss  3.84 | ppl    46.61\n",
      "| epoch  60 |   200/  663 batches | lr 2.50E-04 | ms/batch 227.35 | loss  3.86 | ppl    47.63\n",
      "| epoch  60 |   300/  663 batches | lr 2.50E-04 | ms/batch 227.33 | loss  3.96 | ppl    52.35\n",
      "| epoch  60 |   400/  663 batches | lr 2.50E-04 | ms/batch 222.69 | loss  3.85 | ppl    46.97\n",
      "| epoch  60 |   500/  663 batches | lr 2.50E-04 | ms/batch 218.59 | loss  3.77 | ppl    43.34\n",
      "| epoch  60 |   600/  663 batches | lr 2.50E-04 | ms/batch 222.78 | loss  3.81 | ppl    44.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 163.29s | valid loss  4.23 | valid ppl    68.99\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1e20\n",
    "try:\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(valid_data, args.eval_batch_size)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "            epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        if val_loss < best_val_loss:\n",
    "            with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            lr *= LR_ANNEALING_RATE\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  4.20 | test ppl    66.87\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss = evaluate(test_data, args.test_batch_size)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
